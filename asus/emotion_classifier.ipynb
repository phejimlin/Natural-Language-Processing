{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "server = '140.114.77.15'\n",
    "database = 'ChatService_EmotionTest'\n",
    "username = 'sa'\n",
    "password = '1Qazwsxedc'\n",
    "driver= 'FreeTDS'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pymssql\n",
    "import codecs\n",
    "import jieba\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer, TfidfTransformer\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "\n",
    "conn = pymssql.connect(server=server, user=username, password=password, database=database)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Microsoft SQL Server vNext (CTP1.3) - 14.0.304.138 (X64) \\n\\tFeb 13 2017 16:49:12 \\n\\tCopyright (C) 2016 Microsoft Corporation. All rights reserved.\\n\\ton Linux (Ubuntu 16.04.2 LTS)',)\n"
     ]
    }
   ],
   "source": [
    "cursor = conn.cursor()  \n",
    "cursor.execute('SELECT @@version;')  \n",
    "row = cursor.fetchone() \n",
    "print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('ChatService_EmotionTest', 'dbo', 'ChatList', 'BASE TABLE')\n",
      "ChatService_EmotionTest dbo ChatList\n",
      "ChatService_EmotionTest dbo ChatMessages\n",
      "ChatService_EmotionTest dbo sysdiagrams\n"
     ]
    }
   ],
   "source": [
    "cursor = conn.cursor()  \n",
    "cursor.execute(\"SELECT * FROM INFORMATION_SCHEMA.TABLES WHERE TABLE_TYPE='BASE TABLE'\")  \n",
    "row = cursor.fetchone() \n",
    "print(row)\n",
    "while row:  \n",
    "    print(str(row[0]) + \" \" + str(row[1]) + \" \" + str(row[2]))\n",
    "    row = cursor.fetchone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('ChatId', 1, None, None, None, None, None),\n",
       " ('MessageTime', 4, None, None, None, None, None),\n",
       " ('SenderId', 1, None, None, None, None, None),\n",
       " ('MessageType', 1, None, None, None, None, None),\n",
       " ('Content', 1, None, None, None, None, None),\n",
       " ('MsgId', 3, None, None, None, None, None))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cursor.description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('2361157b-cc70-4bdb-98f6-d17cd7ba9d33', datetime.datetime(2015, 8, 26, 21, 51, 44, 247000), 'D425218C-3E8D-490B-84E9-737E9C58576C', 'text', '還在嗎？', 1)\n",
      "('236309e1-2b95-4ab5-906e-929e5c1f30d8', datetime.datetime(2015, 7, 2, 8, 7, 46, 890000), 'EEC5CFA6-5B32-4281-82D1-3FA06C32CA84', 'text', '你好,padfone s更新5.0後,安裝在SD卡的程式都不能使用', 2)\n",
      "('236309e1-2b95-4ab5-906e-929e5c1f30d8', datetime.datetime(2015, 7, 2, 8, 8, 33, 177000), 'A0110', 'text', '這部份,請您先把這些app移到手機內', 3)\n",
      "('236309e1-2b95-4ab5-906e-929e5c1f30d8', datetime.datetime(2015, 7, 2, 8, 12, 19, 753000), 'A0110', 'text', '那請您在這邊找到後,移重到手機後,再移除', 4)\n",
      "('2363f532-23b6-484a-b3cc-a7a7424822ce', datetime.datetime(2015, 9, 7, 8, 25, 34, 353000), 'CE88B5A2-E432-4B88-9DEE-D4CCB9C28484', 'text', '今年五月底購機,之前偶爾會重開機,近日手機不停發生自動重開機,今天光早上八點左右到八點半,已自動重開機三次,非常討厭,請盡速回覆處理。台北王律師', 5)\n",
      "('22fbb230-9305-4c21-98d8-e7d2877c0d76', datetime.datetime(2016, 9, 29, 9, 48, 59, 263000), 's6262741s84s@gmail.com', 'text', '謝謝', 6)\n",
      "('22fbc764-a52f-4317-a629-16c7ef51e5be', datetime.datetime(2015, 8, 7, 8, 39, 50, 510000), 'A0119', 'text', '幫我點程式安裝的地方按偏好外部儲存空間', 7)\n",
      "('22fbc764-a52f-4317-a629-16c7ef51e5be', datetime.datetime(2015, 8, 7, 8, 40, 30, 23000), 'CF3F9498-A35A-421C-99D6-285AF4606C03', 'text', '那之前安裝的都會到外存嗎', 8)\n",
      "('22fbc764-a52f-4317-a629-16c7ef51e5be', datetime.datetime(2015, 8, 7, 8, 47, 46, 863000), 'A0119', 'text', '[系統公告] 您好! 由於您已超過4分鐘沒有回應,系統將自動將您登出,謝謝您的使用,再見。', 9)\n",
      "('24232416-5fdd-45af-87e9-eadf114e4cca', datetime.datetime(2015, 8, 28, 18, 52, 36, 890000), '36E44842-CF18-4E3B-AC17-6BFEFDB9E3E3', 'text', '我有2個帳戶', 10)\n",
      "('24232416-5fdd-45af-87e9-eadf114e4cca', datetime.datetime(2015, 8, 28, 18, 56, 49, 533000), 'A0125', 'text', '非常不好意思造成您的困擾,這邊跟您說明一下', 11)\n",
      "('24232416-5fdd-45af-87e9-eadf114e4cca', datetime.datetime(2015, 8, 28, 18, 57, 23, 917000), 'A0125', 'text', '由於這邊屬於手機技術諮詢部門,關於活動方面的部分這邊無法給您較完整的回覆,不好意思', 12)\n",
      "('24232416-5fdd-45af-87e9-eadf114e4cca', datetime.datetime(2015, 8, 28, 19, 4, 50, 993000), 'A0125', 'text', '請問您點選忘記密碼後會有系統發送的信件到您的信箱嗎?', 13)\n",
      "('24232416-5fdd-45af-87e9-eadf114e4cca', datetime.datetime(2015, 8, 28, 19, 6, 16, 417000), '36E44842-CF18-4E3B-AC17-6BFEFDB9E3E3', 'text', '出現這樣', 14)\n",
      "('237f14ed-9776-471e-a4d8-0661aad12c82', datetime.datetime(2015, 7, 31, 16, 30, 34, 747000), '9F9843C7-BF69-4F12-AF4B-65D6655B7436', 'text', '一張而已', 15)\n",
      "('237f14ed-9776-471e-a4d8-0661aad12c82', datetime.datetime(2015, 7, 31, 16, 30, 59, 643000), '9F9843C7-BF69-4F12-AF4B-65D6655B7436', 'text', '對', 16)\n",
      "('237f14ed-9776-471e-a4d8-0661aad12c82', datetime.datetime(2015, 7, 31, 16, 42, 37, 847000), 'A0050', 'text', '您剛提供給我的圖片 是在 安全模式下', 17)\n",
      "('237f14ed-9776-471e-a4d8-0661aad12c82', datetime.datetime(2015, 7, 31, 16, 42, 49, 513000), 'A0050', 'text', '這個模式下  是只能出現原廠畫面 無法下載程式的', 18)\n",
      "('23eeae40-dd4d-4414-8ad4-5513a65733ef', datetime.datetime(2016, 11, 8, 15, 54, 29, 147000), 'nldw93@outlook.com', 'text', '??', 19)\n",
      "('23f1f88d-b81d-4382-9774-fd885763bc96', datetime.datetime(2015, 4, 28, 10, 0, 8, 887000), 'A0089', 'text', '您好', 20)\n",
      "('23f2a369-d791-444c-8fe7-761c5a23892e', datetime.datetime(2015, 7, 11, 12, 26, 6, 987000), 'A0128', 'text', '不好意思,華碩沒有實體門市販售新機', 21)\n",
      "('23f2a369-d791-444c-8fe7-761c5a23892e', datetime.datetime(2015, 7, 11, 12, 26, 38, 623000), 'A0128', 'text', '請問還有什麼地方可以為您服務的?', 22)\n",
      "('22ccb2ba-950f-4921-80de-eab946ac0779', datetime.datetime(2016, 3, 6, 14, 51, 36, 213000), 'A95F6691-98C1-4FDA-AB1F-F6F00457D343', 'text', '但不知道怎麼做~', 23)\n",
      "('22ccb2ba-950f-4921-80de-eab946ac0779', datetime.datetime(2016, 3, 6, 14, 53, 13, 360000), 'A0020', 'text', '您好,提供您相關更新資訊 http://www.asus.com/tw/support/FAQ/1009748', 24)\n",
      "('22ccb2ba-950f-4921-80de-eab946ac0779', datetime.datetime(2016, 3, 6, 15, 0, 5, 540000), 'A95F6691-98C1-4FDA-AB1F-F6F00457D343', 'text', '那Android的版本會是？', 25)\n",
      "('22ccb2ba-950f-4921-80de-eab946ac0779', datetime.datetime(2016, 3, 6, 15, 1, 42, 547000), 'A0020', 'text', '不好意思 剛提供您錯誤資訊', 26)\n",
      "('22ccb2ba-950f-4921-80de-eab946ac0779', datetime.datetime(2016, 3, 6, 15, 2, 0, 610000), 'A0020', 'text', '會先更新到Android 4.4 之後 在更新到5.0部分', 27)\n",
      "('23343d7e-2a1c-4ea8-a5f9-7193b7592ddd', datetime.datetime(2015, 8, 15, 16, 40, 3, 923000), 'F720A7A2-063A-4EA0-8D55-78A4D0EE8027', 'text', '還是這樣', 28)\n",
      "('23343d7e-2a1c-4ea8-a5f9-7193b7592ddd', datetime.datetime(2015, 8, 15, 16, 40, 16, 670000), 'A0128', 'text', '請問您是使用哪一支手機呢?', 29)\n",
      "('23343d7e-2a1c-4ea8-a5f9-7193b7592ddd', datetime.datetime(2015, 8, 15, 16, 53, 40, 290000), 'A0128', 'text', '不好意思,請您稍候片刻,我會立即為您查詢,謝謝。', 30)\n"
     ]
    }
   ],
   "source": [
    "cursor = conn.cursor()  \n",
    "cursor.execute(\"select top 30* from ChatMessages\")  \n",
    "row = cursor.fetchone() \n",
    "while row:  \n",
    "    print(row)\n",
    "    row = cursor.fetchone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row = ('1c8fa7f5-0797-4b09-be5a-bbe48d212e69', 'TW', 'mobile', 'MOBILE', datetime.datetime(2015, 8, 19, 20, 51, 31, 857000), datetime.datetime(2015, 8, 19, 21, 15, 31, 227000), 0, 781, '1', datetime.datetime(2015, 8, 19, 21, 4, 37), None)\n",
      "row = ('19c07cd6-e059-49ef-94fd-64a46ec10d23', 'TW', 'mobile', 'MOBILE', datetime.datetime(2015, 7, 25, 18, 41, 44, 267000), datetime.datetime(2015, 7, 25, 18, 54, 26, 227000), 0, 759, '2', datetime.datetime(2015, 7, 25, 18, 47, 38, 170000), None)\n",
      "row = ('19c1466b-10ff-489a-8f60-34c4a1c50a52', 'TW', 'mobile', 'MOBILE', datetime.datetime(2015, 4, 25, 14, 16, 16, 210000), datetime.datetime(2015, 4, 25, 14, 36, 52, 687000), 0, 1233, '2', datetime.datetime(2015, 4, 25, 14, 36, 46, 943000), None)\n",
      "row = ('19eadf8f-46ae-4d10-ab6c-c8e0e72395a3', 'TW', 'mobile', 'MOBILE', datetime.datetime(2015, 7, 27, 13, 53, 40, 257000), datetime.datetime(2015, 7, 27, 14, 1, 13, 423000), 0, 376, '1', datetime.datetime(2015, 7, 27, 14, 0, 10, 83000), None)\n",
      "row = ('17ac9c34-7475-4578-8c36-17272cb03768', 'TW', 'mobile', 'MOBILE', datetime.datetime(2016, 12, 23, 19, 9, 24, 357000), datetime.datetime(2016, 12, 23, 19, 13, 48, 700000), 0, 261, '1', datetime.datetime(2016, 12, 23, 19, 13, 50, 857000), None)\n",
      "row = ('18034969-b286-4e19-b04a-2e868bd31c6e', 'TW', 'mobile', 'MOBILE', datetime.datetime(2016, 3, 4, 22, 49, 30, 27000), datetime.datetime(2016, 3, 4, 23, 0, 5, 97000), 0, 614, '1', datetime.datetime(2016, 3, 4, 23, 0, 4, 727000), None)\n",
      "row = ('183feca1-625e-4ea4-b266-19f6e17afe16', 'TW', 'web', 'MOBILE', datetime.datetime(2015, 7, 11, 20, 28, 52, 723000), datetime.datetime(2015, 7, 11, 20, 28, 59, 633000), 0, 0, '2', datetime.datetime(2015, 7, 11, 20, 29, 46, 253000), None)\n",
      "row = ('186a3626-63d2-4d07-b98e-94f6dd9a80d1', 'TW', 'mobile', 'MOBILE', datetime.datetime(2015, 6, 13, 20, 30, 55, 390000), datetime.datetime(2015, 6, 13, 20, 47, 44, 547000), 0, 1004, '1', datetime.datetime(2015, 6, 13, 20, 40, 29, 207000), None)\n",
      "row = ('19f39395-2a52-40ea-95fd-fd2aeaa9505b', 'TW', 'mobile', 'MOBILE', datetime.datetime(2015, 7, 7, 21, 33, 45, 883000), datetime.datetime(2015, 7, 7, 22, 13, 26, 453000), 0, 1927, '2', datetime.datetime(2015, 7, 7, 21, 49, 58, 193000), None)\n",
      "row = ('19feb2ae-c1bb-481e-8e32-d3337d765388', 'TW', 'mobile', 'MOBILE', datetime.datetime(2016, 12, 8, 23, 27, 38, 117000), datetime.datetime(2016, 12, 8, 23, 33, 0, 357000), 0, 313, '1', datetime.datetime(2016, 12, 8, 23, 33, 0, 10000), None)\n",
      "row = ('1a66b4cd-a87d-4310-9630-d1173ea46a77', 'TW', 'mobile', 'MOBILE', datetime.datetime(2016, 10, 21, 22, 44, 7, 277000), datetime.datetime(2016, 10, 21, 22, 54, 10, 410000), 0, 589, '1', datetime.datetime(2016, 10, 21, 22, 59, 52, 280000), None)\n",
      "row = ('1a7f0081-d7fa-4658-be68-c32715fd2b0a', 'TW', 'mobile', 'MOBILE', datetime.datetime(2016, 3, 31, 22, 43, 2, 190000), datetime.datetime(2016, 3, 31, 22, 50, 22, 80000), 36, 361, '1', datetime.datetime(2016, 3, 31, 22, 50, 34, 993000), None)\n",
      "row = ('1aa4eacf-d21a-4c79-be6b-471fcfe11e03', 'TW', 'mobile', 'MOBILE', datetime.datetime(2015, 6, 6, 12, 25, 57, 460000), datetime.datetime(2015, 6, 6, 12, 42, 26, 970000), 32, 942, '2', datetime.datetime(2015, 6, 6, 12, 34, 30, 367000), None)\n",
      "row = ('19d4927f-dd70-4f3b-b6a1-47ede65a9e14', 'TW', 'mobile', 'MOBILE', datetime.datetime(2016, 1, 3, 22, 21, 55, 963000), datetime.datetime(2016, 1, 3, 22, 22, 2), 0, 0, '1', datetime.datetime(2016, 1, 3, 22, 22, 1, 740000), None)\n",
      "row = ('19ff2346-57d9-4029-ae46-b4d60712877d', 'TW', 'mobile', 'MOBILE', datetime.datetime(2016, 7, 25, 17, 43, 18, 203000), datetime.datetime(2016, 7, 25, 17, 43, 26, 547000), 0, 0, '1', datetime.datetime(2016, 7, 25, 17, 43, 26, 247000), None)\n",
      "row = ('1a10d123-5f7e-4a37-a36f-d2768bd75308', 'TW', 'web', 'MOBILE', datetime.datetime(2016, 8, 19, 15, 35, 35, 127000), datetime.datetime(2016, 8, 19, 16, 5, 17, 400000), 0, 1777, '1', datetime.datetime(2016, 8, 19, 15, 59, 53, 757000), None)\n",
      "row = ('1a7ac882-0469-41e2-846b-20dc6e603e67', 'TW', 'mobile', 'MOBILE', datetime.datetime(2016, 5, 31, 19, 2, 12, 617000), datetime.datetime(2016, 5, 31, 19, 5, 14, 470000), 0, 168, '2', datetime.datetime(2016, 5, 31, 19, 5, 13, 843000), '無法解決我的問題')\n",
      "row = ('180e8ed4-3f11-4e38-9d85-4ad99bea3469', 'TW', 'web', 'MOBILE', datetime.datetime(2016, 10, 14, 22, 46, 47, 153000), datetime.datetime(2016, 10, 14, 23, 10, 11, 90000), 0, 1401, '1', datetime.datetime(2016, 10, 14, 23, 10, 21, 683000), None)\n",
      "row = ('18301503-0c81-4f07-85fb-f08f58b96ed4', 'TW', 'mobile', 'MOBILE', datetime.datetime(2016, 10, 21, 16, 6, 32, 710000), datetime.datetime(2016, 10, 21, 16, 17, 39, 587000), 0, 562, '1', datetime.datetime(2016, 10, 21, 16, 17, 39, 553000), None)\n",
      "row = ('185e5153-fd9c-42a5-83a4-a920128cfb1d', 'TW', 'mobile', 'MOBILE', datetime.datetime(2016, 12, 20, 16, 53, 6, 113000), datetime.datetime(2016, 12, 20, 16, 53, 13, 633000), 0, 0, '1', datetime.datetime(2016, 12, 20, 16, 53, 13, 293000), None)\n",
      "row = ('1a036baa-db4e-4d22-bb2d-25d568416884', 'TW', 'mobile', 'MOBILE', datetime.datetime(2015, 7, 24, 22, 11, 38, 913000), datetime.datetime(2015, 7, 24, 22, 18, 25, 63000), 0, 395, '1', datetime.datetime(2015, 7, 24, 22, 17, 47, 950000), None)\n",
      "row = ('1a5ae00a-0975-470d-8133-dbc1cff2b3da', 'TW', 'mobile', 'MOBILE', datetime.datetime(2015, 9, 22, 13, 6, 52, 290000), datetime.datetime(2015, 9, 22, 13, 18, 32, 790000), 0, 670, '1', datetime.datetime(2015, 9, 22, 13, 8, 52, 980000), None)\n",
      "row = ('19e3329f-1ecc-4215-81b8-46f98afe16c2', 'TW', 'mobile', 'MOBILE', datetime.datetime(2015, 7, 5, 15, 36, 51, 370000), datetime.datetime(2015, 7, 5, 15, 54, 3, 227000), 0, 971, '1', datetime.datetime(2015, 7, 5, 15, 53, 3, 87000), None)\n",
      "row = ('1ac55cca-b80f-46fe-be2f-55ac920da374', 'TW', 'mobile', 'MOBILE', datetime.datetime(2016, 3, 18, 11, 54, 9, 970000), datetime.datetime(2016, 3, 18, 11, 54, 50, 970000), 0, 0, '1', datetime.datetime(2016, 3, 18, 11, 54, 50, 143000), None)\n",
      "row = ('143f3964-570f-4c69-b078-fcc7bbc466a1', 'TW', 'web', 'MOBILE', datetime.datetime(2016, 8, 20, 11, 44, 23, 893000), datetime.datetime(2016, 8, 20, 12, 5, 12, 513000), 0, 1242, '1', datetime.datetime(2016, 8, 20, 12, 6, 48, 557000), None)\n",
      "row = ('147cf752-aa97-4019-8920-8615f48340a2', 'TW', 'mobile', 'MOBILE', datetime.datetime(2015, 6, 13, 21, 6, 11, 857000), datetime.datetime(2015, 6, 13, 21, 22, 36, 187000), 42, 320, '1', datetime.datetime(2015, 6, 13, 21, 12, 9, 640000), None)\n",
      "row = ('1a26b31b-3ed6-4a1a-bb60-53cf6e19c189', 'TW', 'mobile', 'MOBILE', datetime.datetime(2016, 9, 27, 20, 12, 55, 910000), datetime.datetime(2016, 9, 27, 20, 31, 37, 3000), 0, 1119, '1', datetime.datetime(2016, 9, 27, 20, 32, 24, 730000), None)\n",
      "row = ('1ad16cb6-1c26-4c18-856c-a444dfe9c0a7', 'TW', 'mobile', 'MOBILE', datetime.datetime(2015, 5, 20, 11, 50, 50, 73000), datetime.datetime(2015, 5, 20, 11, 54, 13, 657000), 0, 199, '1', datetime.datetime(2015, 5, 20, 11, 54, 8, 887000), None)\n",
      "row = ('1aebb61d-d0fe-45d5-82b0-61be4814fa50', 'TW', 'mobile', 'MOBILE', datetime.datetime(2015, 4, 30, 21, 37, 0, 350000), datetime.datetime(2015, 4, 30, 21, 46, 17, 107000), 3, 430, '1', datetime.datetime(2015, 4, 30, 21, 44, 4, 620000), None)\n",
      "row = ('1a2c51cc-e6c0-4d5b-972d-60af6b81656d', 'TW', 'mobile', 'MOBILE', datetime.datetime(2015, 12, 6, 12, 38, 36, 593000), datetime.datetime(2015, 12, 6, 12, 47, 34, 110000), 0, 532, '1', datetime.datetime(2015, 12, 6, 12, 47, 34, 7000), None)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(('ChatId', 1, None, None, None, None, None),\n",
       " ('TenantId', 1, None, None, None, None, None),\n",
       " ('Channel', 1, None, None, None, None, None),\n",
       " ('Skill', 1, None, None, None, None, None),\n",
       " ('CreateTime', 4, None, None, None, None, None),\n",
       " ('DisposeTime', 4, None, None, None, None, None),\n",
       " ('QueueMS', 3, None, None, None, None, None),\n",
       " ('Duration', 3, None, None, None, None, None),\n",
       " ('Survey', 1, None, None, None, None, None),\n",
       " ('SurveyTime', 4, None, None, None, None, None),\n",
       " ('Suggestion', 1, None, None, None, None, None))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cursor.execute('SELECT top 30* FROM ChatList where Survey is not null')\n",
    "\n",
    "for row in cursor:\n",
    "    print('row = %r' % (row,))\n",
    "cursor.description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44992,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cursor.execute('SELECT count(1) FROM ChatList')\n",
    "cursor.fetchone() \n",
    "\n",
    "cursor.execute('SELECT count(1) FROM ChatList WHERE Survey = 1')\n",
    "cursor.fetchone() \n",
    "\n",
    "# import codecs\n",
    "# cursor.execute('SELECT Content FROM ChatList \\\n",
    "#                JOIN ChatMessages ON ChatList.ChatId = ChatMessages.ChatId \\\n",
    "#                WHERE ChatList.Survey IS NOT NULL AND \\\n",
    "#                LEN(ChatMessages.SenderId) > 5 AND\\\n",
    "#                ChatMessages.MessageType = \\'text\\'\\\n",
    "#                ORDER BY ChatMessages.ChatId\\\n",
    "#                ')\n",
    "# f = codecs.open(\"./test_data/msg.txt\",\"w\", \"utf-8-sig\")\n",
    "# for msg in cursor.fetchall():\n",
    "#     f.write(msg[0]+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cursor = conn.cursor()  \n",
    "cursor.execute(\"SELECT ChatList.ChatId, ChatMessages.SenderId , ChatMessages.Content from ChatList \\\n",
    "                JOIN ChatMessages ON ChatList.ChatId = ChatMessages.ChatId \\\n",
    "                WHERE ChatList.Survey = 1 AND ChatMessages.MessageType = \\'text\\' \\\n",
    "                ORDER BY ChatMessages.ChatId\")  \n",
    "row = cursor.fetchone() \n",
    "pos_data_sets = {}\n",
    "while row:\n",
    "    if row[0] in pos_data_sets:\n",
    "        pos_data_sets[row[0]].append(row)\n",
    "    else:\n",
    "        pos_data_sets[row[0]] = [row]\n",
    "    row = cursor.fetchone()\n",
    "\n",
    "for key in list(pos_data_sets.keys()):\n",
    "    user_content_array = []\n",
    "    for data in pos_data_sets[key]:\n",
    "        if data[1] == None or len(data[1]) > 5:\n",
    "            user_content_array.append(data[2])\n",
    "    pos_data_sets[key] = user_content_array\n",
    "\n",
    "for key in list(pos_data_sets.keys()):\n",
    "    if len(pos_data_sets[key]) == 0:\n",
    "        del pos_data_sets[key]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['不知怎麼設定', 'ZF2', '滿意,謝謝你', '才能收到', '就是MMS沒有圖片', '文字收到', '還是要,放在卡1', '原來如此', '放到sim1', '之前用S3,可以收到mms', '應該不是中華電信的問題', '才能收到']\n",
      "['那一個小時預約快修 的部分是?', '這樣要怎麼處理呢', '所以就有機會 當日維修好囉', '及最下面三個 案件  也沒反應', 'ZF2', '一個小時快修的部分', ' 恩恩  對', '不是', '如果送修的話 有可能當天就好嗎', '請問螢幕觸控按了沒反應', '沒使用單手模式下   任何情況那三個按鍵都沒反應', '還有螢幕中間部分區塊按了也沒反應', '恩   好   我了解了', '謝謝你', '550ML', '現在我只能轉換成單手操作變成小螢幕的虛擬三個觸控按鈕才能使用那三個案件的功能', '是因為沒辦法按 我才轉換成單手模式的']\n",
      "['維修地點是板橋皇家沒錯', '瞭解, 感謝您~~~', '您好,請問官網上的維修進度查詢 如果顯示可以去取件了 是否就表示維修完成了呢？', '因為之前都會有簡訊通知 但我一直沒收到 剛剛線上查詢了 發現昨天就可以取件了', '江選帆', 'TWA3610915']\n",
      "['ZENFONE 2', '你好 可以線上查詢保固日期嗎', 'F5AZFG21A099', '好的 謝謝']\n",
      "['已傳輸到sd卡了', '檔案要放到那裡?', '我先試試,有問題再來請問您們', 'tks', '如已有解壓會有什麼狀況嗎？', '請問要如何手動更新下載軔體?', '我的手機是 ZenFone6', 'sd卡可以?', '這裡對嗎？', '已解壓縮檔要移除嗎？', 'ok ']\n",
      "['你好', '我要把目前使用的手機號碼轉到另外一支,出門不用帶二支', '簡單明瞭', '我要將手機轉接,收到錯誤訊息,不能轉接出去', '簡單說我要將我的手機號碼轉至另一支', '我有開網路', 'zf3', '把我的電話轉到另外一支', '二支手機', '但不行', '謝了,了解', '不能轉接到另一支手機', '來電轉接無法轉接', '886', '網路傳回非預期回應', '通話設定==>來電轉接==>一律轉接==>輸入號碼後按開啟,出現網路傳回非預期回應']\n",
      "['謝謝您', '請問一下', 'zenfone2 4G/32G版的可以去大陸使用通話功能嗎？', '因官方的論壇是有說不能使用4G上網,但我不清楚是否可以使用2G或3G功能？', '謝謝您', '好', '好的']\n",
      "['我的螢幕變這樣', '要怎麼送修', '好的', '那要怎麼看sn序號', '保固有免費維修嗎', '恩', '黑白的', '那要怎麼送過去', '蘇敬舜、0937365683、台南市善化區中興路117號', '恩', 'Zenfone5', '那維修一次螢幕要多少', '請問一下官網買的保故是多久', '手機電原鍵拖落、螢幕無法顯示無法處控', '好', '我的sn:E9AZCY162071', '好的', '可以指定地方嗎', '好', '官網', '對', '維修大約要多久']\n",
      "['哪我請問一下喔  因為我昨天掃毒這個程式都會停在80% 83% 95% 這個是什麼問題啊？', '嗯嗯 商店下載ㄉ', '沒有了 謝謝 有需要 我會在問ㄉ', '謝謝妳 辛苦了 再見:)^^', '我按滿意 :)  ^^  ', '操作？', '那個我想請問一下DIY大師這個程式會不會跟手機系統程式不合然後造成程式當機？', '為什麼這個程每次掃毒都停在80% 不然就是83% 95%呢？', '妳好', '不好意思我想請問一下', '好 等我一下喔', '可是手機常常重新開機會不會影響手機的程式以及壽命？', 'Zenfone2', '是說掃毒嗎？', '可以了:)', '太久沒重開機？  意思是說 手機過一段時間要重課開的意思？', '好 我知道了 謝謝喔 ^^', '是因為程式太多嗎？', '剛剛上一個客服叫我把全部程式快取清楚我已經用了 現在要怎麼辦？', '恩好 我知道了  謝謝妳:)  ^^', ':) ^^']\n",
      "['我要問的是,平常的變壓器多數為1a /2a', '好的', '你好,', '我上面的問題,請問您看得到嗎', '我知道Asus買手機附送的變壓器,是輸出1.5A', '謝謝您的回答', '我知道。當然每個廠商都會建議用原廠的', '我想請問,我可不可以使用變壓器2A 的部分為手機充電呢？', '我的手機是zenfone6']\n",
      "['謝謝', '您好 請問高雄哪裡有展示ZenFone 3呢', '沒有了', '嗯嗯 好 ']\n",
      "['你好我啟動安全後', '哈囉？', '好的', '還是打不開內鏡', '可是我過保固兩個月了', '這樣如果維修鏡頭費用大概會多少', '謝謝', '所以沒有辦法知道換鏡的大概報價嗎？']\n",
      "['途中突然不能動,螢幕背景變成黑色', '我有定期檢查是否有更新', '不好意思剛剛打錯網址了', '重開機時會一直震動', '之後才能正常開機', '這樣是該如何處理', '有', '不好意思我不太知道在哪裡', '請問在使用手機時', '之後過了一會兒全暗了', '都不能動', 'zenfone 5', '要去哪裡更新', '對應版本', '.78?']\n",
      "['啊羅哈,傑夫', '喔,好,', '我想問,除了網路商店哪裡可以買到實體原廠充電線', 'z5', '喔,好吧,那之後會有嗎', '好的', '只有1小時快修,需要拿到皇家現場嗎', '請問有原廠快速充電嗎', '只有一組 線+充電器嗎,還是有分開單售', '有價錢嗎']\n",
      "['我想知道ASUS ZenFone 3 (ZE552KL)目前購買有何優惠', '我想知道ASUS ZenFone 3 (ZE552KL)目前購買有何優惠']\n",
      "['另外問單曲最長能放多久?', '單曲無限制?', '1600ms是多九?', '音樂播放時間']\n",
      "['好的謝謝您😆', '請問要怎麼關閉zenlife']\n",
      "['只要三四個影片就當,為何用蘋果4不會貴公司手機才發生,所以想了解,應該跟line無關吧！', '那些資訊', 'line傳拍影片', '李國慶,0928284789 kuoching86841478@yahoo.com.tw何謂機台,板本', '感謝', '雲端的檔案下載是否會比較慢,我有兩個雲端硬碟華碩,及Google+。很久就反應,覺得是否運算速度不夠', '手機才買半年,客服及時通', '我希望支持國貨,才希望能找出毛病出在那,', '不在旁邊要找 下次如何聯絡', 'ZenFone2', '以前用蘋果不會,應該沒有。可以幫我查', '怎麼找', '為何上傳多張影片,會要重新傳,已經反應多次,還是無解。', '上傳太久就要重來  551', '是否這個', '感謝,掰掰']\n",
      "['這問題哪時會解決', '升級為6.0.1後,如何把應用呈式移到SD卡內', '那要如何處理', '還有其他辦法可移嗎']\n",
      "['請問台中市有直營服務站嗎？', '嗯', '沒有,我自行過去謝謝']\n",
      "['我的zenfone2會有閃屏的狀況', '那該怎麼確定自己的手機還在保固內呢', '面板的畫面會閃爍,有時還有停在特定畫面的狀況', '您好,我有手機方面的問題', '好的,謝謝您~']\n"
     ]
    }
   ],
   "source": [
    "for index, row in enumerate(pos_data_sets):\n",
    "    if index>20:\n",
    "        break\n",
    "    print(pos_data_sets[row])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16270"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "8135*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = []\n",
    "satisfied_degree = []\n",
    "for index, key in enumerate(pos_data_sets):\n",
    "#     if index>16270:\n",
    "#         break\n",
    "    corpus.append(' '.join(jieba.cut(' '.join(pos_data_sets[key]), cut_all=False)))\n",
    "    satisfied_degree.append(1)\n",
    "\n",
    "for key in neg_data_sets:\n",
    "    corpus.append(' '.join(jieba.cut(' '.join(neg_data_sets[key]), cut_all=False)))\n",
    "    satisfied_degree.append(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24406"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.先將正面與負面的 使用者字詞 利用TFIDF 算出Bag of word\n",
    "## 2.再將正負面丟去Train Classier \n",
    "## 3.在跟助教給的情緒LIB 比對分數看看\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import plotly.graph_objs as go\n",
    "from plotly.graph_objs import *\n",
    "import plotly.plotly as py\n",
    "import plotly.figure_factory as ff\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "np_corpus = np.array(corpus)\n",
    "np_satisfied_degree = np.array(satisfied_degree)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    np_corpus, np_satisfied_degree, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# scikit-learn example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating the bag of words...\n",
      "\n",
      "(17084, 500)\n",
      "(7322, 500)\n"
     ]
    }
   ],
   "source": [
    "print(\"Creating the bag of words...\\n\")\n",
    "\n",
    "# Initialize the \"CountVectorizer\" object, which is scikit-learn's\n",
    "# bag of words tool.  \n",
    "vectorizer = CountVectorizer(analyzer = \"word\",   \\\n",
    "                             tokenizer = None,    \\\n",
    "                             preprocessor = None, \\\n",
    "                             stop_words = None,   \\\n",
    "                             max_features = 500) \n",
    "\n",
    "# fit_transform() does two functions: First, it fits the model\n",
    "# and learns the vocabulary; second, it transforms our training data\n",
    "# into feature vectors. The input to fit_transform should be a list of \n",
    "# strings.\n",
    "train_data_features = vectorizer.fit_transform(X_train)\n",
    "test_data_features = vectorizer.transform(X_test)\n",
    "\n",
    "print(train_data_features.shape)\n",
    "print(test_data_features.shape)\n",
    "\n",
    "# Numpy arrays are easy to work with, so convert the result to an \n",
    "# array\n",
    "train_data_features = train_data_features.toarray()\n",
    "test_data_features = test_data_features.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyze = vectorizer.build_analyzer()\n",
    "analyze(\"華碩 品質 好差\")\n",
    "len(train_data_features[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17084, 300)\n",
      "(7322, 300)\n"
     ]
    }
   ],
   "source": [
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(train_data_features)\n",
    "print(X_train_tfidf.shape)\n",
    "X_test_tfidf = tfidf_transformer.transform(test_data_features)\n",
    "print(X_test_tfidf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.81      0.15      0.25      2390\n",
      "          1       0.70      0.98      0.82      4932\n",
      "\n",
      "avg / total       0.74      0.71      0.63      7322\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Naive_bayes \n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB().fit(X_train_tfidf, y_train)\n",
    "\n",
    "predicted = clf.predict(X_test_tfidf)\n",
    "\n",
    "print(metrics.classification_report(y_test, predicted, target_names=['0', '1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the SVM...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.66      0.65      0.65      2390\n",
      "          1       0.83      0.84      0.83      4932\n",
      "\n",
      "avg / total       0.77      0.78      0.77      7322\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SVM\n",
    "print(\"Training the SVM...\")\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
    "\n",
    "clf = LinearSVC().fit(X_train_tfidf, y_train)\n",
    "predicted = clf.predict(X_test_tfidf)\n",
    "print(metrics.classification_report(y_test, predicted, target_names=['0', '1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the DecisionTree...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.61      0.78      0.68      2390\n",
      "          1       0.88      0.76      0.81      4932\n",
      "\n",
      "avg / total       0.79      0.77      0.77      7322\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Training the DecisionTree...\")\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# criterion : impurity function\n",
    "# max_depth : maximum depth of tree\n",
    "# random_state : seed of random number generator\n",
    "tree = DecisionTreeClassifier(criterion='entropy', \n",
    "                              max_depth=3, \n",
    "                              random_state=0)\n",
    "tree.fit(X_train_tfidf, y_train)\n",
    "predicted = tree.predict(X_test_tfidf)\n",
    "print(metrics.classification_report(y_test, predicted, target_names=['0', '1']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the random forest...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.65      0.66      2390\n",
      "          1       0.83      0.84      0.84      4932\n",
      "\n",
      "avg / total       0.78      0.78      0.78      7322\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Training the random forest...\")\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Initialize a Random Forest classifier with 100 trees\n",
    "forest = RandomForestClassifier(n_estimators = 100) \n",
    "\n",
    "# Fit the forest to the training set, using the bag of words as \n",
    "# features and the sentiment labels as the response variable\n",
    "#\n",
    "# This may take a few minutes to run\n",
    "forest = forest.fit( X_train_tfidf,  y_train)\n",
    "\n",
    "predicted = forest.predict(X_test_tfidf)\n",
    "\n",
    "print(metrics.classification_report(y_test, predicted, target_names=['0', '1']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manually Playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_data = [['爛公司 華碩 品質 無法 解決 問題'], ['這公司 好爛 惹我生氣 煩欸 幹 無法 解決 問題'], ['不知怎麼設定', 'ZF2', '滿意,謝謝你', '才能收到', '就是MMS沒有圖片', '文字收到', '還是要,放在卡1', '原來如此', '放到sim1', '之前用S3,可以收到mms', '應該不是中華電信的問題', '才能收到'],\n",
    "['那一個小時預約快修 的部分是?', '這樣要怎麼處理呢', '所以就有機會 當日維修好囉', '及最下面三個 案件  也沒反應', 'ZF2', '一個小時快修的部分', ' 恩恩  對', '不是', '如果送修的話 有可能當天就好嗎', '請問螢幕觸控按了沒反應', '沒使用單手模式下   任何情況那三個按鍵都沒反應', '還有螢幕中間部分區塊按了也沒反應', '恩   好   我了解了', '謝謝你', '550ML', '現在我只能轉換成單手操作變成小螢幕的虛擬三個觸控按鈕才能使用那三個案件的功能', '是因為沒辦法按 我才轉換成單手模式的'],\n",
    "['維修地點是板橋皇家沒錯', '瞭解, 感謝您~~~', '您好,請問官網上的維修進度查詢 如果顯示可以去取件了 是否就表示維修完成了呢？', '因為之前都會有簡訊通知 但我一直沒收到 剛剛線上查詢了 發現昨天就可以取件了', '江選帆', 'TWA3610915'],\n",
    "['ZENFONE 2', '你好 可以線上查詢保固日期嗎', 'F5AZFG21A099', '好的 謝謝'],\n",
    "['已傳輸到sd卡了', '檔案要放到那裡?', '我先試試,有問題再來請問您們', 'tks', '如已有解壓會有什麼狀況嗎？', '請問要如何手動更新下載軔體?', '我的手機是 ZenFone6', 'sd卡可以?', '這裡對嗎？', '已解壓縮檔要移除嗎？', 'ok '],\n",
    "['你好', '我要把目前使用的手機號碼轉到另外一支,出門不用帶二支', '簡單明瞭', '我要將手機轉接,收到錯誤訊息,不能轉接出去', '簡單說我要將我的手機號碼轉至另一支', '我有開網路', 'zf3', '把我的電話轉到另外一支', '二支手機', '但不行', '謝了,了解', '不能轉接到另一支手機', '來電轉接無法轉接', '886', '網路傳回非預期回應', '通話設定==>來電轉接==>一律轉接==>輸入號碼後按開啟,出現網路傳回非預期回應'],\n",
    "['謝謝您', '請問一下', 'zenfone2 4G/32G版的可以去大陸使用通話功能嗎？', '因官方的論壇是有說不能使用4G上網,但我不清楚是否可以使用2G或3G功能？', '謝謝您', '好', '好的'],\n",
    "['我的螢幕變這樣', '要怎麼送修', '好的', '那要怎麼看sn序號', '保固有免費維修嗎', '恩', '黑白的', '那要怎麼送過去', '蘇敬舜、0937365683、台南市善化區中興路117號', '恩', 'Zenfone5', '那維修一次螢幕要多少', '請問一下官網買的保故是多久', '手機電原鍵拖落、螢幕無法顯示無法處控', '好', '我的sn:E9AZCY162071', '好的', '可以指定地方嗎', '好', '官網', '對', '維修大約要多久'],\n",
    "['哪我請問一下喔  因為我昨天掃毒這個程式都會停在80% 83% 95% 這個是什麼問題啊？', '嗯嗯 商店下載ㄉ', '沒有了 謝謝 有需要 我會在問ㄉ', '謝謝妳 辛苦了 再見:)^^', '我按滿意 :)  ^^  ', '操作？', '那個我想請問一下DIY大師這個程式會不會跟手機系統程式不合然後造成程式當機？', '為什麼這個程每次掃毒都停在80% 不然就是83% 95%呢？', '妳好', '不好意思我想請問一下', '好 等我一下喔', '可是手機常常重新開機會不會影響手機的程式以及壽命？', 'Zenfone2', '是說掃毒嗎？', '可以了:)', '太久沒重開機？  意思是說 手機過一段時間要重課開的意思？', '好 我知道了 謝謝喔 ^^', '是因為程式太多嗎？', '剛剛上一個客服叫我把全部程式快取清楚我已經用了 現在要怎麼辦？', '恩好 我知道了  謝謝妳:)  ^^', ':) ^^'],\n",
    "['我要問的是,平常的變壓器多數為1a /2a', '好的', '你好,', '我上面的問題,請問您看得到嗎', '我知道Asus買手機附送的變壓器,是輸出1.5A', '謝謝您的回答', '我知道。當然每個廠商都會建議用原廠的', '我想請問,我可不可以使用變壓器2A 的部分為手機充電呢？', '我的手機是zenfone6'],\n",
    "['謝謝', '您好 請問高雄哪裡有展示ZenFone 3呢', '沒有了', '嗯嗯 好 '],\n",
    "['你好我啟動安全後', '哈囉？', '好的', '還是打不開內鏡', '可是我過保固兩個月了', '這樣如果維修鏡頭費用大概會多少', '謝謝', '所以沒有辦法知道換鏡的大概報價嗎？'],\n",
    "['途中突然不能動,螢幕背景變成黑色', '我有定期檢查是否有更新', '不好意思剛剛打錯網址了', '重開機時會一直震動', '之後才能正常開機', '這樣是該如何處理', '有', '不好意思我不太知道在哪裡', '請問在使用手機時', '之後過了一會兒全暗了', '都不能動', 'zenfone 5', '要去哪裡更新', '對應版本', '.78?'],\n",
    "['啊羅哈,傑夫', '喔,好,', '我想問,除了網路商店哪裡可以買到實體原廠充電線', 'z5', '喔,好吧,那之後會有嗎', '好的', '只有1小時快修,需要拿到皇家現場嗎', '請問有原廠快速充電嗎', '只有一組 線+充電器嗎,還是有分開單售', '有價錢嗎'],\n",
    "['我想知道ASUS ZenFone 3 (ZE552KL)目前購買有何優惠', '我想知道ASUS ZenFone 3 (ZE552KL)目前購買有何優惠'],\n",
    "['另外問單曲最長能放多久?', '單曲無限制?', '1600ms是多九?', '音樂播放時間'],\n",
    "['好的謝謝您😆', '請問要怎麼關閉zenlife'],\n",
    "['只要三四個影片就當,為何用蘋果4不會貴公司手機才發生,所以想了解,應該跟line無關吧！', '那些資訊', 'line傳拍影片', '李國慶,0928284789 kuoching86841478@yahoo.com.tw何謂機台,板本', '感謝', '雲端的檔案下載是否會比較慢,我有兩個雲端硬碟華碩,及Google+。很久就反應,覺得是否運算速度不夠', '手機才買半年,客服及時通', '我希望支持國貨,才希望能找出毛病出在那,', '不在旁邊要找 下次如何聯絡', 'ZenFone2', '以前用蘋果不會,應該沒有。可以幫我查', '怎麼找', '為何上傳多張影片,會要重新傳,已經反應多次,還是無解。', '上傳太久就要重來  551', '是否這個', '感謝,掰掰'],\n",
    "['這問題哪時會解決', '升級為6.0.1後,如何把應用呈式移到SD卡內', '那要如何處理', '還有其他辦法可移嗎'],\n",
    "['請問台中市有直營服務站嗎？', '嗯', '沒有,我自行過去謝謝'],\n",
    "['我的zenfone2會有閃屏的狀況', '那該怎麼確定自己的手機還在保固內呢', '面板的畫面會閃爍,有時還有停在特定畫面的狀況', '您好,我有手機方面的問題', '好的,謝謝您~']]\n",
    "test_data_X = []\n",
    "for data in test_data:\n",
    "    test_data_X.append(' '.join(jieba.cut(' '.join(data), cut_all=False)))\n",
    "test_data_Y = np.ones(21)\n",
    "test_data_Y = np.append([-1, -1], test_data_Y)\n",
    "test_data_X = np.array(test_data_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  1, -1, ...,  1,  1, -1])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.68      0.65      0.66      2390\n",
      "          1       0.83      0.85      0.84      4932\n",
      "\n",
      "avg / total       0.78      0.79      0.78      7322\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "text_clf = Pipeline([('vect', CountVectorizer(\n",
    "                             analyzer = \"word\",   \\\n",
    "                             tokenizer = None,    \\\n",
    "                             preprocessor = None, \\\n",
    "                             stop_words = None,   \\\n",
    "                             max_features = 500)),\n",
    "                      ('tfidf', TfidfTransformer()),\n",
    "                      ('clf', RandomForestClassifier(n_estimators = 100)),\n",
    "])\n",
    "\n",
    "text_clf = text_clf.fit( X_train,  y_train)\n",
    "\n",
    "\n",
    "predicted = text_clf.predict(X_test)\n",
    "print(metrics.classification_report(y_test, predicted, target_names=['0', '1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.50      1.00      0.67         2\n",
      "          1       1.00      0.90      0.95        21\n",
      "\n",
      "avg / total       0.96      0.91      0.93        23\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predicted = text_clf.predict(test_data_X)\n",
    "print(metrics.classification_report(test_data_Y, predicted, target_names=['0', '1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.87      ,  0.13      ],\n",
       "       [ 0.85      ,  0.15      ],\n",
       "       [ 0.2       ,  0.8       ],\n",
       "       [ 0.2       ,  0.8       ],\n",
       "       [ 0.12      ,  0.88      ],\n",
       "       [ 0.01      ,  0.99      ],\n",
       "       [ 0.11      ,  0.89      ],\n",
       "       [ 0.59      ,  0.41      ],\n",
       "       [ 0.14      ,  0.86      ],\n",
       "       [ 0.45      ,  0.55      ],\n",
       "       [ 0.1       ,  0.9       ],\n",
       "       [ 0.12      ,  0.88      ],\n",
       "       [ 0.188     ,  0.812     ],\n",
       "       [ 0.02      ,  0.98      ],\n",
       "       [ 0.38      ,  0.62      ],\n",
       "       [ 0.49708661,  0.50291339],\n",
       "       [ 0.4075    ,  0.5925    ],\n",
       "       [ 0.51713974,  0.48286026],\n",
       "       [ 0.105     ,  0.895     ],\n",
       "       [ 0.15      ,  0.85      ],\n",
       "       [ 0.21416667,  0.78583333],\n",
       "       [ 0.08      ,  0.92      ],\n",
       "       [ 0.12      ,  0.88      ]])"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clf.predict_proba(test_data_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pretraining with TFIDF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_bar_chart(input_list, chart_title):\n",
    "    x_axis = []\n",
    "    y_axis = []\n",
    "    for item in input_list:\n",
    "        x_axis.append(item[0])\n",
    "        y_axis.append(item[1])\n",
    "    data = [go.Bar(\n",
    "                x = x_axis,\n",
    "                y = y_axis\n",
    "        )]\n",
    "\n",
    "    layout = go.Layout(\n",
    "        title = chart_title,\n",
    "    )\n",
    "    fig = go.Figure(data=data, layout=layout)\n",
    "    py.iplot(fig, filename='basic-bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def display_scores(vectorizer, tfidf_result):\n",
    "    # http://stackoverflow.com/questions/16078015/\n",
    "    scores = zip(vectorizer.get_feature_names(),\n",
    "                 np.asarray(tfidf_result.sum(axis=0)).ravel())\n",
    "    sorted_scores = sorted(scores, key=lambda x: x[1], reverse=True)\n",
    "    index_scores = []\n",
    "    for index, item in enumerate(sorted_scores):\n",
    "        index_scores.append((index, item[1]))\n",
    "        \n",
    "    generate_bar_chart(index_scores, 'TFIDF Score')\n",
    "    return sorted_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Utilizing TFIDF to delete useless words.\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf = tfidf_vectorizer.fit_transform(corpus)\n",
    "tfidf_features = tfidf_vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/phejimlin/anaconda3/envs/tensorflow_3.5/lib/python3.5/site-packages/plotly/plotly/plotly.py:218: UserWarning:\n",
      "\n",
      "Woah there! Look at all those points! Due to browser limitations, the Plotly SVG drawing functions have a hard time graphing more than 500k data points for line charts, or 40k points for other types of charts. Here are some suggestions:\n",
      "(1) Use the `plotly.graph_objs.Scattergl` trace object to generate a WebGl graph.\n",
      "(2) Trying using the image API to return an image instead of a graph URL\n",
      "(3) Use matplotlib\n",
      "(4) See if you can create your visualization with fewer data points\n",
      "\n",
      "If the visualization you're using aggregates points (e.g., box plot, histogram, etc.) you can disregard this warning.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High five! You successfuly sent some data to your account on plotly. View your plot in your browser at https://plot.ly/~phejimlin/0 or inside your plot.ly account where it is named 'basic-bar'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/phejimlin/anaconda3/envs/tensorflow_3.5/lib/python3.5/site-packages/plotly/api/v1/clientresp.py:40: UserWarning:\n",
      "\n",
      "Estimated Draw Time Slow\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sorted_scores = display_scores(tfidf_vectorizer, tfidf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Bag of words to select top n = 400\n",
    "bag_of_words = [word[0] for word in sorted_scores[:401]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating the bag of words...\n",
      "\n",
      "(17084, 401)\n",
      "(7322, 401)\n"
     ]
    }
   ],
   "source": [
    "print(\"Creating the bag of words...\\n\")\n",
    "\n",
    "# Initialize the \"CountVectorizer\" object, which is scikit-learn's\n",
    "# bag of words tool.  \n",
    "vectorizer = CountVectorizer(vocabulary=bag_of_words) \n",
    "\n",
    "# fit_transform() does two functions: First, it fits the model\n",
    "# and learns the vocabulary; second, it transforms our training data\n",
    "# into feature vectors. The input to fit_transform should be a list of \n",
    "# strings.\n",
    "train_data_features = vectorizer.fit_transform(X_train)\n",
    "test_data_features = vectorizer.transform(X_test)\n",
    "\n",
    "print(train_data_features.shape)\n",
    "print(test_data_features.shape)\n",
    "\n",
    "# Numpy arrays are easy to work with, so convert the result to an \n",
    "# array\n",
    "train_data_features = train_data_features.toarray()\n",
    "test_data_features = test_data_features.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the random forest...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.63      0.65      2390\n",
      "          1       0.83      0.85      0.84      4932\n",
      "\n",
      "avg / total       0.78      0.78      0.78      7322\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Training the random forest...\")\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Initialize a Random Forest classifier with 100 trees\n",
    "forest = RandomForestClassifier(n_estimators = 100) \n",
    "\n",
    "# Fit the forest to the training set, using the bag of words as \n",
    "# features and the sentiment labels as the response variable\n",
    "#\n",
    "# This may take a few minutes to run\n",
    "forest = forest.fit(train_data_features,  y_train)\n",
    "\n",
    "predicted = forest.predict(test_data_features)\n",
    "\n",
    "print(metrics.classification_report(y_test, predicted, target_names=['0', '1']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.62      0.64      2390\n",
      "          1       0.82      0.85      0.84      4932\n",
      "\n",
      "avg / total       0.77      0.78      0.77      7322\n",
      "\n",
      "[[ 0.9         0.1       ]\n",
      " [ 0.94        0.06      ]\n",
      " [ 0.1         0.9       ]\n",
      " [ 0.31        0.69      ]\n",
      " [ 0.09        0.91      ]\n",
      " [ 0.005       0.995     ]\n",
      " [ 0.24        0.76      ]\n",
      " [ 0.44        0.56      ]\n",
      " [ 0.19        0.81      ]\n",
      " [ 0.39        0.61      ]\n",
      " [ 0.16        0.84      ]\n",
      " [ 0.08        0.92      ]\n",
      " [ 0.05        0.95      ]\n",
      " [ 0.05        0.95      ]\n",
      " [ 0.56        0.44      ]\n",
      " [ 0.46485714  0.53514286]\n",
      " [ 0.33        0.67      ]\n",
      " [ 0.72437121  0.27562879]\n",
      " [ 0.24616667  0.75383333]\n",
      " [ 0.22        0.78      ]\n",
      " [ 0.28333333  0.71666667]\n",
      " [ 0.          1.        ]\n",
      " [ 0.13        0.87      ]]\n"
     ]
    }
   ],
   "source": [
    "text_clf = Pipeline([('vect', CountVectorizer(vocabulary=bag_of_words)),\n",
    "                      ('clf', RandomForestClassifier(n_estimators = 100)),\n",
    "])\n",
    "\n",
    "text_clf = text_clf.fit(X_train,  y_train)\n",
    "\n",
    "\n",
    "predicted = text_clf.predict(X_test)\n",
    "print(metrics.classification_report(y_test, predicted, target_names=['0', '1']))\n",
    "print(text_clf.predict_proba(test_data_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "# now you can save it to a file\n",
    "with open('TFIDF_RandomForestClassifier.pkl', 'wb') as f:\n",
    "    pickle.dump(text_clf, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.62      0.46      0.53      2390\n",
      "          1       0.77      0.86      0.81      4932\n",
      "\n",
      "avg / total       0.72      0.73      0.72      7322\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Naive_bayes \n",
    "Multinomial_clf = Pipeline([('vect', CountVectorizer(vocabulary=bag_of_words)),\n",
    "                      ('clf', MultinomialNB()),\n",
    "])\n",
    "Multinomial_clf = Multinomial_clf.fit(X_train, y_train)\n",
    "\n",
    "predicted = Multinomial_clf.predict(X_test)\n",
    "\n",
    "print(metrics.classification_report(y_test, predicted, target_names=['0', '1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('Naive_bayes_Classifier.pkl', 'wb') as f:\n",
    "    pickle.dump(Multinomial_clf, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the SVM...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.62      0.46      0.53      2390\n",
      "          1       0.77      0.86      0.81      4932\n",
      "\n",
      "avg / total       0.72      0.73      0.72      7322\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SVM\n",
    "print(\"Training the SVM...\")\n",
    "LinearSVC_clf = Pipeline([('vect', CountVectorizer(vocabulary=bag_of_words)),\n",
    "                      ('clf', LinearSVC()),\n",
    "])\n",
    "\n",
    "LinearSVC_clf = LinearSVC_clf.fit(X_train, y_train)\n",
    "predicted = clf.predict(X_test)\n",
    "print(metrics.classification_report(y_test, predicted, target_names=['0', '1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('LinearSVC_Classifier.pkl', 'wb') as f:\n",
    "    pickle.dump(LinearSVC_clf, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the DecisionTree...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.61      0.78      0.69      2390\n",
      "          1       0.88      0.76      0.82      4932\n",
      "\n",
      "avg / total       0.79      0.77      0.77      7322\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Training the DecisionTree...\")\n",
    "DecisionTree_clf = Pipeline([('vect', CountVectorizer(vocabulary=bag_of_words)),\n",
    "                      ('clf', DecisionTreeClassifier(criterion='entropy', \n",
    "                              max_depth=3, \n",
    "                              random_state=0)),\n",
    "])\n",
    "\n",
    "# criterion : impurity function\n",
    "# max_depth : maximum depth of tree\n",
    "# random_state : seed of random number generator\n",
    "DecisionTree_clf=DecisionTree_clf.fit(X_train, y_train)\n",
    "predicted = DecisionTree_clf.predict(X_test)\n",
    "print(metrics.classification_report(y_test, predicted, target_names=['0', '1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('DecisionTree_Classifier.pkl', 'wb') as f:\n",
    "    pickle.dump(DecisionTree_clf, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load modle with pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# and later you can load it\n",
    "with open('TFIDF_RandomForestClassifier.pkl', 'rb') as f:\n",
    "    clf = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.9         0.1       ]\n",
      " [ 0.94        0.06      ]\n",
      " [ 0.1         0.9       ]\n",
      " [ 0.31        0.69      ]\n",
      " [ 0.09        0.91      ]\n",
      " [ 0.005       0.995     ]\n",
      " [ 0.24        0.76      ]\n",
      " [ 0.44        0.56      ]\n",
      " [ 0.19        0.81      ]\n",
      " [ 0.39        0.61      ]\n",
      " [ 0.16        0.84      ]\n",
      " [ 0.08        0.92      ]\n",
      " [ 0.05        0.95      ]\n",
      " [ 0.05        0.95      ]\n",
      " [ 0.56        0.44      ]\n",
      " [ 0.46485714  0.53514286]\n",
      " [ 0.33        0.67      ]\n",
      " [ 0.72437121  0.27562879]\n",
      " [ 0.24616667  0.75383333]\n",
      " [ 0.22        0.78      ]\n",
      " [ 0.28333333  0.71666667]\n",
      " [ 0.          1.        ]\n",
      " [ 0.13        0.87      ]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.62      0.64      2390\n",
      "          1       0.82      0.85      0.84      4932\n",
      "\n",
      "avg / total       0.77      0.78      0.77      7322\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(clf.predict_proba(test_data_X))\n",
    "predicted = clf.predict(X_test)\n",
    "print(metrics.classification_report(y_test, predicted, target_names=['0', '1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
