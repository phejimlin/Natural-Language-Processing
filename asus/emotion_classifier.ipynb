{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "server = '140.114.77.15'\n",
    "database = 'ChatService_EmotionTest'\n",
    "username = 'sa'\n",
    "password = '1Qazwsxedc'\n",
    "driver= 'FreeTDS'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pymssql\n",
    "import codecs\n",
    "import jieba\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer, TfidfTransformer\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "\n",
    "conn = pymssql.connect(server=server, user=username, password=password, database=database)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Microsoft SQL Server vNext (CTP1.3) - 14.0.304.138 (X64) \\n\\tFeb 13 2017 16:49:12 \\n\\tCopyright (C) 2016 Microsoft Corporation. All rights reserved.\\n\\ton Linux (Ubuntu 16.04.2 LTS)',)\n"
     ]
    }
   ],
   "source": [
    "cursor = conn.cursor()  \n",
    "cursor.execute('SELECT @@version;')  \n",
    "row = cursor.fetchone() \n",
    "print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('ChatService_EmotionTest', 'dbo', 'ChatList', 'BASE TABLE')\n",
      "ChatService_EmotionTest dbo ChatList\n",
      "ChatService_EmotionTest dbo ChatMessages\n",
      "ChatService_EmotionTest dbo sysdiagrams\n"
     ]
    }
   ],
   "source": [
    "cursor = conn.cursor()  \n",
    "cursor.execute(\"SELECT * FROM INFORMATION_SCHEMA.TABLES WHERE TABLE_TYPE='BASE TABLE'\")  \n",
    "row = cursor.fetchone() \n",
    "print(row)\n",
    "while row:  \n",
    "    print(str(row[0]) + \" \" + str(row[1]) + \" \" + str(row[2]))\n",
    "    row = cursor.fetchone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('ChatId', 1, None, None, None, None, None),\n",
       " ('MessageTime', 4, None, None, None, None, None),\n",
       " ('SenderId', 1, None, None, None, None, None),\n",
       " ('MessageType', 1, None, None, None, None, None),\n",
       " ('Content', 1, None, None, None, None, None),\n",
       " ('MsgId', 3, None, None, None, None, None))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cursor.description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('2361157b-cc70-4bdb-98f6-d17cd7ba9d33', datetime.datetime(2015, 8, 26, 21, 51, 44, 247000), 'D425218C-3E8D-490B-84E9-737E9C58576C', 'text', 'é‚„åœ¨å—ï¼Ÿ', 1)\n",
      "('236309e1-2b95-4ab5-906e-929e5c1f30d8', datetime.datetime(2015, 7, 2, 8, 7, 46, 890000), 'EEC5CFA6-5B32-4281-82D1-3FA06C32CA84', 'text', 'ä½ å¥½,padfone sæ›´æ–°5.0å¾Œ,å®‰è£åœ¨SDå¡çš„ç¨‹å¼éƒ½ä¸èƒ½ä½¿ç”¨', 2)\n",
      "('236309e1-2b95-4ab5-906e-929e5c1f30d8', datetime.datetime(2015, 7, 2, 8, 8, 33, 177000), 'A0110', 'text', 'é€™éƒ¨ä»½,è«‹æ‚¨å…ˆæŠŠé€™äº›appç§»åˆ°æ‰‹æ©Ÿå…§', 3)\n",
      "('236309e1-2b95-4ab5-906e-929e5c1f30d8', datetime.datetime(2015, 7, 2, 8, 12, 19, 753000), 'A0110', 'text', 'é‚£è«‹æ‚¨åœ¨é€™é‚Šæ‰¾åˆ°å¾Œ,ç§»é‡åˆ°æ‰‹æ©Ÿå¾Œ,å†ç§»é™¤', 4)\n",
      "('2363f532-23b6-484a-b3cc-a7a7424822ce', datetime.datetime(2015, 9, 7, 8, 25, 34, 353000), 'CE88B5A2-E432-4B88-9DEE-D4CCB9C28484', 'text', 'ä»Šå¹´äº”æœˆåº•è³¼æ©Ÿ,ä¹‹å‰å¶çˆ¾æœƒé‡é–‹æ©Ÿ,è¿‘æ—¥æ‰‹æ©Ÿä¸åœç™¼ç”Ÿè‡ªå‹•é‡é–‹æ©Ÿ,ä»Šå¤©å…‰æ—©ä¸Šå…«é»å·¦å³åˆ°å…«é»åŠ,å·²è‡ªå‹•é‡é–‹æ©Ÿä¸‰æ¬¡,éå¸¸è¨å­,è«‹ç›¡é€Ÿå›è¦†è™•ç†ã€‚å°åŒ—ç‹å¾‹å¸«', 5)\n",
      "('22fbb230-9305-4c21-98d8-e7d2877c0d76', datetime.datetime(2016, 9, 29, 9, 48, 59, 263000), 's6262741s84s@gmail.com', 'text', 'è¬è¬', 6)\n",
      "('22fbc764-a52f-4317-a629-16c7ef51e5be', datetime.datetime(2015, 8, 7, 8, 39, 50, 510000), 'A0119', 'text', 'å¹«æˆ‘é»ç¨‹å¼å®‰è£çš„åœ°æ–¹æŒ‰åå¥½å¤–éƒ¨å„²å­˜ç©ºé–“', 7)\n",
      "('22fbc764-a52f-4317-a629-16c7ef51e5be', datetime.datetime(2015, 8, 7, 8, 40, 30, 23000), 'CF3F9498-A35A-421C-99D6-285AF4606C03', 'text', 'é‚£ä¹‹å‰å®‰è£çš„éƒ½æœƒåˆ°å¤–å­˜å—', 8)\n",
      "('22fbc764-a52f-4317-a629-16c7ef51e5be', datetime.datetime(2015, 8, 7, 8, 47, 46, 863000), 'A0119', 'text', '[ç³»çµ±å…¬å‘Š] æ‚¨å¥½! ç”±æ–¼æ‚¨å·²è¶…é4åˆ†é˜æ²’æœ‰å›æ‡‰,ç³»çµ±å°‡è‡ªå‹•å°‡æ‚¨ç™»å‡º,è¬è¬æ‚¨çš„ä½¿ç”¨,å†è¦‹ã€‚', 9)\n",
      "('24232416-5fdd-45af-87e9-eadf114e4cca', datetime.datetime(2015, 8, 28, 18, 52, 36, 890000), '36E44842-CF18-4E3B-AC17-6BFEFDB9E3E3', 'text', 'æˆ‘æœ‰2å€‹å¸³æˆ¶', 10)\n",
      "('24232416-5fdd-45af-87e9-eadf114e4cca', datetime.datetime(2015, 8, 28, 18, 56, 49, 533000), 'A0125', 'text', 'éå¸¸ä¸å¥½æ„æ€é€ æˆæ‚¨çš„å›°æ“¾,é€™é‚Šè·Ÿæ‚¨èªªæ˜ä¸€ä¸‹', 11)\n",
      "('24232416-5fdd-45af-87e9-eadf114e4cca', datetime.datetime(2015, 8, 28, 18, 57, 23, 917000), 'A0125', 'text', 'ç”±æ–¼é€™é‚Šå±¬æ–¼æ‰‹æ©ŸæŠ€è¡“è«®è©¢éƒ¨é–€,é—œæ–¼æ´»å‹•æ–¹é¢çš„éƒ¨åˆ†é€™é‚Šç„¡æ³•çµ¦æ‚¨è¼ƒå®Œæ•´çš„å›è¦†,ä¸å¥½æ„æ€', 12)\n",
      "('24232416-5fdd-45af-87e9-eadf114e4cca', datetime.datetime(2015, 8, 28, 19, 4, 50, 993000), 'A0125', 'text', 'è«‹å•æ‚¨é»é¸å¿˜è¨˜å¯†ç¢¼å¾Œæœƒæœ‰ç³»çµ±ç™¼é€çš„ä¿¡ä»¶åˆ°æ‚¨çš„ä¿¡ç®±å—?', 13)\n",
      "('24232416-5fdd-45af-87e9-eadf114e4cca', datetime.datetime(2015, 8, 28, 19, 6, 16, 417000), '36E44842-CF18-4E3B-AC17-6BFEFDB9E3E3', 'text', 'å‡ºç¾é€™æ¨£', 14)\n",
      "('237f14ed-9776-471e-a4d8-0661aad12c82', datetime.datetime(2015, 7, 31, 16, 30, 34, 747000), '9F9843C7-BF69-4F12-AF4B-65D6655B7436', 'text', 'ä¸€å¼µè€Œå·²', 15)\n",
      "('237f14ed-9776-471e-a4d8-0661aad12c82', datetime.datetime(2015, 7, 31, 16, 30, 59, 643000), '9F9843C7-BF69-4F12-AF4B-65D6655B7436', 'text', 'å°', 16)\n",
      "('237f14ed-9776-471e-a4d8-0661aad12c82', datetime.datetime(2015, 7, 31, 16, 42, 37, 847000), 'A0050', 'text', 'æ‚¨å‰›æä¾›çµ¦æˆ‘çš„åœ–ç‰‡ æ˜¯åœ¨ å®‰å…¨æ¨¡å¼ä¸‹', 17)\n",
      "('237f14ed-9776-471e-a4d8-0661aad12c82', datetime.datetime(2015, 7, 31, 16, 42, 49, 513000), 'A0050', 'text', 'é€™å€‹æ¨¡å¼ä¸‹  æ˜¯åªèƒ½å‡ºç¾åŸå» ç•«é¢ ç„¡æ³•ä¸‹è¼‰ç¨‹å¼çš„', 18)\n",
      "('23eeae40-dd4d-4414-8ad4-5513a65733ef', datetime.datetime(2016, 11, 8, 15, 54, 29, 147000), 'nldw93@outlook.com', 'text', '??', 19)\n",
      "('23f1f88d-b81d-4382-9774-fd885763bc96', datetime.datetime(2015, 4, 28, 10, 0, 8, 887000), 'A0089', 'text', 'æ‚¨å¥½', 20)\n",
      "('23f2a369-d791-444c-8fe7-761c5a23892e', datetime.datetime(2015, 7, 11, 12, 26, 6, 987000), 'A0128', 'text', 'ä¸å¥½æ„æ€,è¯ç¢©æ²’æœ‰å¯¦é«”é–€å¸‚è²©å”®æ–°æ©Ÿ', 21)\n",
      "('23f2a369-d791-444c-8fe7-761c5a23892e', datetime.datetime(2015, 7, 11, 12, 26, 38, 623000), 'A0128', 'text', 'è«‹å•é‚„æœ‰ä»€éº¼åœ°æ–¹å¯ä»¥ç‚ºæ‚¨æœå‹™çš„?', 22)\n",
      "('22ccb2ba-950f-4921-80de-eab946ac0779', datetime.datetime(2016, 3, 6, 14, 51, 36, 213000), 'A95F6691-98C1-4FDA-AB1F-F6F00457D343', 'text', 'ä½†ä¸çŸ¥é“æ€éº¼åš~', 23)\n",
      "('22ccb2ba-950f-4921-80de-eab946ac0779', datetime.datetime(2016, 3, 6, 14, 53, 13, 360000), 'A0020', 'text', 'æ‚¨å¥½,æä¾›æ‚¨ç›¸é—œæ›´æ–°è³‡è¨Š http://www.asus.com/tw/support/FAQ/1009748', 24)\n",
      "('22ccb2ba-950f-4921-80de-eab946ac0779', datetime.datetime(2016, 3, 6, 15, 0, 5, 540000), 'A95F6691-98C1-4FDA-AB1F-F6F00457D343', 'text', 'é‚£Androidçš„ç‰ˆæœ¬æœƒæ˜¯ï¼Ÿ', 25)\n",
      "('22ccb2ba-950f-4921-80de-eab946ac0779', datetime.datetime(2016, 3, 6, 15, 1, 42, 547000), 'A0020', 'text', 'ä¸å¥½æ„æ€ å‰›æä¾›æ‚¨éŒ¯èª¤è³‡è¨Š', 26)\n",
      "('22ccb2ba-950f-4921-80de-eab946ac0779', datetime.datetime(2016, 3, 6, 15, 2, 0, 610000), 'A0020', 'text', 'æœƒå…ˆæ›´æ–°åˆ°Android 4.4 ä¹‹å¾Œ åœ¨æ›´æ–°åˆ°5.0éƒ¨åˆ†', 27)\n",
      "('23343d7e-2a1c-4ea8-a5f9-7193b7592ddd', datetime.datetime(2015, 8, 15, 16, 40, 3, 923000), 'F720A7A2-063A-4EA0-8D55-78A4D0EE8027', 'text', 'é‚„æ˜¯é€™æ¨£', 28)\n",
      "('23343d7e-2a1c-4ea8-a5f9-7193b7592ddd', datetime.datetime(2015, 8, 15, 16, 40, 16, 670000), 'A0128', 'text', 'è«‹å•æ‚¨æ˜¯ä½¿ç”¨å“ªä¸€æ”¯æ‰‹æ©Ÿå‘¢?', 29)\n",
      "('23343d7e-2a1c-4ea8-a5f9-7193b7592ddd', datetime.datetime(2015, 8, 15, 16, 53, 40, 290000), 'A0128', 'text', 'ä¸å¥½æ„æ€,è«‹æ‚¨ç¨å€™ç‰‡åˆ»,æˆ‘æœƒç«‹å³ç‚ºæ‚¨æŸ¥è©¢,è¬è¬ã€‚', 30)\n"
     ]
    }
   ],
   "source": [
    "cursor = conn.cursor()  \n",
    "cursor.execute(\"select top 30* from ChatMessages\")  \n",
    "row = cursor.fetchone() \n",
    "while row:  \n",
    "    print(row)\n",
    "    row = cursor.fetchone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row = ('1c8fa7f5-0797-4b09-be5a-bbe48d212e69', 'TW', 'mobile', 'MOBILE', datetime.datetime(2015, 8, 19, 20, 51, 31, 857000), datetime.datetime(2015, 8, 19, 21, 15, 31, 227000), 0, 781, '1', datetime.datetime(2015, 8, 19, 21, 4, 37), None)\n",
      "row = ('19c07cd6-e059-49ef-94fd-64a46ec10d23', 'TW', 'mobile', 'MOBILE', datetime.datetime(2015, 7, 25, 18, 41, 44, 267000), datetime.datetime(2015, 7, 25, 18, 54, 26, 227000), 0, 759, '2', datetime.datetime(2015, 7, 25, 18, 47, 38, 170000), None)\n",
      "row = ('19c1466b-10ff-489a-8f60-34c4a1c50a52', 'TW', 'mobile', 'MOBILE', datetime.datetime(2015, 4, 25, 14, 16, 16, 210000), datetime.datetime(2015, 4, 25, 14, 36, 52, 687000), 0, 1233, '2', datetime.datetime(2015, 4, 25, 14, 36, 46, 943000), None)\n",
      "row = ('19eadf8f-46ae-4d10-ab6c-c8e0e72395a3', 'TW', 'mobile', 'MOBILE', datetime.datetime(2015, 7, 27, 13, 53, 40, 257000), datetime.datetime(2015, 7, 27, 14, 1, 13, 423000), 0, 376, '1', datetime.datetime(2015, 7, 27, 14, 0, 10, 83000), None)\n",
      "row = ('17ac9c34-7475-4578-8c36-17272cb03768', 'TW', 'mobile', 'MOBILE', datetime.datetime(2016, 12, 23, 19, 9, 24, 357000), datetime.datetime(2016, 12, 23, 19, 13, 48, 700000), 0, 261, '1', datetime.datetime(2016, 12, 23, 19, 13, 50, 857000), None)\n",
      "row = ('18034969-b286-4e19-b04a-2e868bd31c6e', 'TW', 'mobile', 'MOBILE', datetime.datetime(2016, 3, 4, 22, 49, 30, 27000), datetime.datetime(2016, 3, 4, 23, 0, 5, 97000), 0, 614, '1', datetime.datetime(2016, 3, 4, 23, 0, 4, 727000), None)\n",
      "row = ('183feca1-625e-4ea4-b266-19f6e17afe16', 'TW', 'web', 'MOBILE', datetime.datetime(2015, 7, 11, 20, 28, 52, 723000), datetime.datetime(2015, 7, 11, 20, 28, 59, 633000), 0, 0, '2', datetime.datetime(2015, 7, 11, 20, 29, 46, 253000), None)\n",
      "row = ('186a3626-63d2-4d07-b98e-94f6dd9a80d1', 'TW', 'mobile', 'MOBILE', datetime.datetime(2015, 6, 13, 20, 30, 55, 390000), datetime.datetime(2015, 6, 13, 20, 47, 44, 547000), 0, 1004, '1', datetime.datetime(2015, 6, 13, 20, 40, 29, 207000), None)\n",
      "row = ('19f39395-2a52-40ea-95fd-fd2aeaa9505b', 'TW', 'mobile', 'MOBILE', datetime.datetime(2015, 7, 7, 21, 33, 45, 883000), datetime.datetime(2015, 7, 7, 22, 13, 26, 453000), 0, 1927, '2', datetime.datetime(2015, 7, 7, 21, 49, 58, 193000), None)\n",
      "row = ('19feb2ae-c1bb-481e-8e32-d3337d765388', 'TW', 'mobile', 'MOBILE', datetime.datetime(2016, 12, 8, 23, 27, 38, 117000), datetime.datetime(2016, 12, 8, 23, 33, 0, 357000), 0, 313, '1', datetime.datetime(2016, 12, 8, 23, 33, 0, 10000), None)\n",
      "row = ('1a66b4cd-a87d-4310-9630-d1173ea46a77', 'TW', 'mobile', 'MOBILE', datetime.datetime(2016, 10, 21, 22, 44, 7, 277000), datetime.datetime(2016, 10, 21, 22, 54, 10, 410000), 0, 589, '1', datetime.datetime(2016, 10, 21, 22, 59, 52, 280000), None)\n",
      "row = ('1a7f0081-d7fa-4658-be68-c32715fd2b0a', 'TW', 'mobile', 'MOBILE', datetime.datetime(2016, 3, 31, 22, 43, 2, 190000), datetime.datetime(2016, 3, 31, 22, 50, 22, 80000), 36, 361, '1', datetime.datetime(2016, 3, 31, 22, 50, 34, 993000), None)\n",
      "row = ('1aa4eacf-d21a-4c79-be6b-471fcfe11e03', 'TW', 'mobile', 'MOBILE', datetime.datetime(2015, 6, 6, 12, 25, 57, 460000), datetime.datetime(2015, 6, 6, 12, 42, 26, 970000), 32, 942, '2', datetime.datetime(2015, 6, 6, 12, 34, 30, 367000), None)\n",
      "row = ('19d4927f-dd70-4f3b-b6a1-47ede65a9e14', 'TW', 'mobile', 'MOBILE', datetime.datetime(2016, 1, 3, 22, 21, 55, 963000), datetime.datetime(2016, 1, 3, 22, 22, 2), 0, 0, '1', datetime.datetime(2016, 1, 3, 22, 22, 1, 740000), None)\n",
      "row = ('19ff2346-57d9-4029-ae46-b4d60712877d', 'TW', 'mobile', 'MOBILE', datetime.datetime(2016, 7, 25, 17, 43, 18, 203000), datetime.datetime(2016, 7, 25, 17, 43, 26, 547000), 0, 0, '1', datetime.datetime(2016, 7, 25, 17, 43, 26, 247000), None)\n",
      "row = ('1a10d123-5f7e-4a37-a36f-d2768bd75308', 'TW', 'web', 'MOBILE', datetime.datetime(2016, 8, 19, 15, 35, 35, 127000), datetime.datetime(2016, 8, 19, 16, 5, 17, 400000), 0, 1777, '1', datetime.datetime(2016, 8, 19, 15, 59, 53, 757000), None)\n",
      "row = ('1a7ac882-0469-41e2-846b-20dc6e603e67', 'TW', 'mobile', 'MOBILE', datetime.datetime(2016, 5, 31, 19, 2, 12, 617000), datetime.datetime(2016, 5, 31, 19, 5, 14, 470000), 0, 168, '2', datetime.datetime(2016, 5, 31, 19, 5, 13, 843000), 'ç„¡æ³•è§£æ±ºæˆ‘çš„å•é¡Œ')\n",
      "row = ('180e8ed4-3f11-4e38-9d85-4ad99bea3469', 'TW', 'web', 'MOBILE', datetime.datetime(2016, 10, 14, 22, 46, 47, 153000), datetime.datetime(2016, 10, 14, 23, 10, 11, 90000), 0, 1401, '1', datetime.datetime(2016, 10, 14, 23, 10, 21, 683000), None)\n",
      "row = ('18301503-0c81-4f07-85fb-f08f58b96ed4', 'TW', 'mobile', 'MOBILE', datetime.datetime(2016, 10, 21, 16, 6, 32, 710000), datetime.datetime(2016, 10, 21, 16, 17, 39, 587000), 0, 562, '1', datetime.datetime(2016, 10, 21, 16, 17, 39, 553000), None)\n",
      "row = ('185e5153-fd9c-42a5-83a4-a920128cfb1d', 'TW', 'mobile', 'MOBILE', datetime.datetime(2016, 12, 20, 16, 53, 6, 113000), datetime.datetime(2016, 12, 20, 16, 53, 13, 633000), 0, 0, '1', datetime.datetime(2016, 12, 20, 16, 53, 13, 293000), None)\n",
      "row = ('1a036baa-db4e-4d22-bb2d-25d568416884', 'TW', 'mobile', 'MOBILE', datetime.datetime(2015, 7, 24, 22, 11, 38, 913000), datetime.datetime(2015, 7, 24, 22, 18, 25, 63000), 0, 395, '1', datetime.datetime(2015, 7, 24, 22, 17, 47, 950000), None)\n",
      "row = ('1a5ae00a-0975-470d-8133-dbc1cff2b3da', 'TW', 'mobile', 'MOBILE', datetime.datetime(2015, 9, 22, 13, 6, 52, 290000), datetime.datetime(2015, 9, 22, 13, 18, 32, 790000), 0, 670, '1', datetime.datetime(2015, 9, 22, 13, 8, 52, 980000), None)\n",
      "row = ('19e3329f-1ecc-4215-81b8-46f98afe16c2', 'TW', 'mobile', 'MOBILE', datetime.datetime(2015, 7, 5, 15, 36, 51, 370000), datetime.datetime(2015, 7, 5, 15, 54, 3, 227000), 0, 971, '1', datetime.datetime(2015, 7, 5, 15, 53, 3, 87000), None)\n",
      "row = ('1ac55cca-b80f-46fe-be2f-55ac920da374', 'TW', 'mobile', 'MOBILE', datetime.datetime(2016, 3, 18, 11, 54, 9, 970000), datetime.datetime(2016, 3, 18, 11, 54, 50, 970000), 0, 0, '1', datetime.datetime(2016, 3, 18, 11, 54, 50, 143000), None)\n",
      "row = ('143f3964-570f-4c69-b078-fcc7bbc466a1', 'TW', 'web', 'MOBILE', datetime.datetime(2016, 8, 20, 11, 44, 23, 893000), datetime.datetime(2016, 8, 20, 12, 5, 12, 513000), 0, 1242, '1', datetime.datetime(2016, 8, 20, 12, 6, 48, 557000), None)\n",
      "row = ('147cf752-aa97-4019-8920-8615f48340a2', 'TW', 'mobile', 'MOBILE', datetime.datetime(2015, 6, 13, 21, 6, 11, 857000), datetime.datetime(2015, 6, 13, 21, 22, 36, 187000), 42, 320, '1', datetime.datetime(2015, 6, 13, 21, 12, 9, 640000), None)\n",
      "row = ('1a26b31b-3ed6-4a1a-bb60-53cf6e19c189', 'TW', 'mobile', 'MOBILE', datetime.datetime(2016, 9, 27, 20, 12, 55, 910000), datetime.datetime(2016, 9, 27, 20, 31, 37, 3000), 0, 1119, '1', datetime.datetime(2016, 9, 27, 20, 32, 24, 730000), None)\n",
      "row = ('1ad16cb6-1c26-4c18-856c-a444dfe9c0a7', 'TW', 'mobile', 'MOBILE', datetime.datetime(2015, 5, 20, 11, 50, 50, 73000), datetime.datetime(2015, 5, 20, 11, 54, 13, 657000), 0, 199, '1', datetime.datetime(2015, 5, 20, 11, 54, 8, 887000), None)\n",
      "row = ('1aebb61d-d0fe-45d5-82b0-61be4814fa50', 'TW', 'mobile', 'MOBILE', datetime.datetime(2015, 4, 30, 21, 37, 0, 350000), datetime.datetime(2015, 4, 30, 21, 46, 17, 107000), 3, 430, '1', datetime.datetime(2015, 4, 30, 21, 44, 4, 620000), None)\n",
      "row = ('1a2c51cc-e6c0-4d5b-972d-60af6b81656d', 'TW', 'mobile', 'MOBILE', datetime.datetime(2015, 12, 6, 12, 38, 36, 593000), datetime.datetime(2015, 12, 6, 12, 47, 34, 110000), 0, 532, '1', datetime.datetime(2015, 12, 6, 12, 47, 34, 7000), None)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(('ChatId', 1, None, None, None, None, None),\n",
       " ('TenantId', 1, None, None, None, None, None),\n",
       " ('Channel', 1, None, None, None, None, None),\n",
       " ('Skill', 1, None, None, None, None, None),\n",
       " ('CreateTime', 4, None, None, None, None, None),\n",
       " ('DisposeTime', 4, None, None, None, None, None),\n",
       " ('QueueMS', 3, None, None, None, None, None),\n",
       " ('Duration', 3, None, None, None, None, None),\n",
       " ('Survey', 1, None, None, None, None, None),\n",
       " ('SurveyTime', 4, None, None, None, None, None),\n",
       " ('Suggestion', 1, None, None, None, None, None))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cursor.execute('SELECT top 30* FROM ChatList where Survey is not null')\n",
    "\n",
    "for row in cursor:\n",
    "    print('row = %r' % (row,))\n",
    "cursor.description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44992,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cursor.execute('SELECT count(1) FROM ChatList')\n",
    "cursor.fetchone() \n",
    "\n",
    "cursor.execute('SELECT count(1) FROM ChatList WHERE Survey = 1')\n",
    "cursor.fetchone() \n",
    "\n",
    "# import codecs\n",
    "# cursor.execute('SELECT Content FROM ChatList \\\n",
    "#                JOIN ChatMessages ON ChatList.ChatId = ChatMessages.ChatId \\\n",
    "#                WHERE ChatList.Survey IS NOT NULL AND \\\n",
    "#                LEN(ChatMessages.SenderId) > 5 AND\\\n",
    "#                ChatMessages.MessageType = \\'text\\'\\\n",
    "#                ORDER BY ChatMessages.ChatId\\\n",
    "#                ')\n",
    "# f = codecs.open(\"./test_data/msg.txt\",\"w\", \"utf-8-sig\")\n",
    "# for msg in cursor.fetchall():\n",
    "#     f.write(msg[0]+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cursor = conn.cursor()  \n",
    "cursor.execute(\"SELECT ChatList.ChatId, ChatMessages.SenderId , ChatMessages.Content from ChatList \\\n",
    "                JOIN ChatMessages ON ChatList.ChatId = ChatMessages.ChatId \\\n",
    "                WHERE ChatList.Survey = 1 AND ChatMessages.MessageType = \\'text\\' \\\n",
    "                ORDER BY ChatMessages.ChatId\")  \n",
    "row = cursor.fetchone() \n",
    "pos_data_sets = {}\n",
    "while row:\n",
    "    if row[0] in pos_data_sets:\n",
    "        pos_data_sets[row[0]].append(row)\n",
    "    else:\n",
    "        pos_data_sets[row[0]] = [row]\n",
    "    row = cursor.fetchone()\n",
    "\n",
    "for key in list(pos_data_sets.keys()):\n",
    "    user_content_array = []\n",
    "    for data in pos_data_sets[key]:\n",
    "        if data[1] == None or len(data[1]) > 5:\n",
    "            user_content_array.append(data[2])\n",
    "    pos_data_sets[key] = user_content_array\n",
    "\n",
    "for key in list(pos_data_sets.keys()):\n",
    "    if len(pos_data_sets[key]) == 0:\n",
    "        del pos_data_sets[key]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ä¸çŸ¥æ€éº¼è¨­å®š', 'ZF2', 'æ»¿æ„,è¬è¬ä½ ', 'æ‰èƒ½æ”¶åˆ°', 'å°±æ˜¯MMSæ²’æœ‰åœ–ç‰‡', 'æ–‡å­—æ”¶åˆ°', 'é‚„æ˜¯è¦,æ”¾åœ¨å¡1', 'åŸä¾†å¦‚æ­¤', 'æ”¾åˆ°sim1', 'ä¹‹å‰ç”¨S3,å¯ä»¥æ”¶åˆ°mms', 'æ‡‰è©²ä¸æ˜¯ä¸­è¯é›»ä¿¡çš„å•é¡Œ', 'æ‰èƒ½æ”¶åˆ°']\n",
      "['é‚£ä¸€å€‹å°æ™‚é ç´„å¿«ä¿® çš„éƒ¨åˆ†æ˜¯?', 'é€™æ¨£è¦æ€éº¼è™•ç†å‘¢', 'æ‰€ä»¥å°±æœ‰æ©Ÿæœƒ ç•¶æ—¥ç¶­ä¿®å¥½å›‰', 'åŠæœ€ä¸‹é¢ä¸‰å€‹ æ¡ˆä»¶  ä¹Ÿæ²’åæ‡‰', 'ZF2', 'ä¸€å€‹å°æ™‚å¿«ä¿®çš„éƒ¨åˆ†', ' æ©æ©  å°', 'ä¸æ˜¯', 'å¦‚æœé€ä¿®çš„è©± æœ‰å¯èƒ½ç•¶å¤©å°±å¥½å—', 'è«‹å•è¢å¹•è§¸æ§æŒ‰äº†æ²’åæ‡‰', 'æ²’ä½¿ç”¨å–®æ‰‹æ¨¡å¼ä¸‹   ä»»ä½•æƒ…æ³é‚£ä¸‰å€‹æŒ‰éµéƒ½æ²’åæ‡‰', 'é‚„æœ‰è¢å¹•ä¸­é–“éƒ¨åˆ†å€å¡ŠæŒ‰äº†ä¹Ÿæ²’åæ‡‰', 'æ©   å¥½   æˆ‘äº†è§£äº†', 'è¬è¬ä½ ', '550ML', 'ç¾åœ¨æˆ‘åªèƒ½è½‰æ›æˆå–®æ‰‹æ“ä½œè®Šæˆå°è¢å¹•çš„è™›æ“¬ä¸‰å€‹è§¸æ§æŒ‰éˆ•æ‰èƒ½ä½¿ç”¨é‚£ä¸‰å€‹æ¡ˆä»¶çš„åŠŸèƒ½', 'æ˜¯å› ç‚ºæ²’è¾¦æ³•æŒ‰ æˆ‘æ‰è½‰æ›æˆå–®æ‰‹æ¨¡å¼çš„']\n",
      "['ç¶­ä¿®åœ°é»æ˜¯æ¿æ©‹çš‡å®¶æ²’éŒ¯', 'ç­è§£, æ„Ÿè¬æ‚¨~~~', 'æ‚¨å¥½,è«‹å•å®˜ç¶²ä¸Šçš„ç¶­ä¿®é€²åº¦æŸ¥è©¢ å¦‚æœé¡¯ç¤ºå¯ä»¥å»å–ä»¶äº† æ˜¯å¦å°±è¡¨ç¤ºç¶­ä¿®å®Œæˆäº†å‘¢ï¼Ÿ', 'å› ç‚ºä¹‹å‰éƒ½æœƒæœ‰ç°¡è¨Šé€šçŸ¥ ä½†æˆ‘ä¸€ç›´æ²’æ”¶åˆ° å‰›å‰›ç·šä¸ŠæŸ¥è©¢äº† ç™¼ç¾æ˜¨å¤©å°±å¯ä»¥å–ä»¶äº†', 'æ±Ÿé¸å¸†', 'TWA3610915']\n",
      "['ZENFONE 2', 'ä½ å¥½ å¯ä»¥ç·šä¸ŠæŸ¥è©¢ä¿å›ºæ—¥æœŸå—', 'F5AZFG21A099', 'å¥½çš„ è¬è¬']\n",
      "['å·²å‚³è¼¸åˆ°sdå¡äº†', 'æª”æ¡ˆè¦æ”¾åˆ°é‚£è£¡?', 'æˆ‘å…ˆè©¦è©¦,æœ‰å•é¡Œå†ä¾†è«‹å•æ‚¨å€‘', 'tks', 'å¦‚å·²æœ‰è§£å£“æœƒæœ‰ä»€éº¼ç‹€æ³å—ï¼Ÿ', 'è«‹å•è¦å¦‚ä½•æ‰‹å‹•æ›´æ–°ä¸‹è¼‰è»”é«”?', 'æˆ‘çš„æ‰‹æ©Ÿæ˜¯ ZenFone6', 'sdå¡å¯ä»¥?', 'é€™è£¡å°å—ï¼Ÿ', 'å·²è§£å£“ç¸®æª”è¦ç§»é™¤å—ï¼Ÿ', 'ok ']\n",
      "['ä½ å¥½', 'æˆ‘è¦æŠŠç›®å‰ä½¿ç”¨çš„æ‰‹æ©Ÿè™Ÿç¢¼è½‰åˆ°å¦å¤–ä¸€æ”¯,å‡ºé–€ä¸ç”¨å¸¶äºŒæ”¯', 'ç°¡å–®æ˜ç­', 'æˆ‘è¦å°‡æ‰‹æ©Ÿè½‰æ¥,æ”¶åˆ°éŒ¯èª¤è¨Šæ¯,ä¸èƒ½è½‰æ¥å‡ºå»', 'ç°¡å–®èªªæˆ‘è¦å°‡æˆ‘çš„æ‰‹æ©Ÿè™Ÿç¢¼è½‰è‡³å¦ä¸€æ”¯', 'æˆ‘æœ‰é–‹ç¶²è·¯', 'zf3', 'æŠŠæˆ‘çš„é›»è©±è½‰åˆ°å¦å¤–ä¸€æ”¯', 'äºŒæ”¯æ‰‹æ©Ÿ', 'ä½†ä¸è¡Œ', 'è¬äº†,äº†è§£', 'ä¸èƒ½è½‰æ¥åˆ°å¦ä¸€æ”¯æ‰‹æ©Ÿ', 'ä¾†é›»è½‰æ¥ç„¡æ³•è½‰æ¥', '886', 'ç¶²è·¯å‚³å›éé æœŸå›æ‡‰', 'é€šè©±è¨­å®š==>ä¾†é›»è½‰æ¥==>ä¸€å¾‹è½‰æ¥==>è¼¸å…¥è™Ÿç¢¼å¾ŒæŒ‰é–‹å•Ÿ,å‡ºç¾ç¶²è·¯å‚³å›éé æœŸå›æ‡‰']\n",
      "['è¬è¬æ‚¨', 'è«‹å•ä¸€ä¸‹', 'zenfone2 4G/32Gç‰ˆçš„å¯ä»¥å»å¤§é™¸ä½¿ç”¨é€šè©±åŠŸèƒ½å—ï¼Ÿ', 'å› å®˜æ–¹çš„è«–å£‡æ˜¯æœ‰èªªä¸èƒ½ä½¿ç”¨4Gä¸Šç¶²,ä½†æˆ‘ä¸æ¸…æ¥šæ˜¯å¦å¯ä»¥ä½¿ç”¨2Gæˆ–3GåŠŸèƒ½ï¼Ÿ', 'è¬è¬æ‚¨', 'å¥½', 'å¥½çš„']\n",
      "['æˆ‘çš„è¢å¹•è®Šé€™æ¨£', 'è¦æ€éº¼é€ä¿®', 'å¥½çš„', 'é‚£è¦æ€éº¼çœ‹snåºè™Ÿ', 'ä¿å›ºæœ‰å…è²»ç¶­ä¿®å—', 'æ©', 'é»‘ç™½çš„', 'é‚£è¦æ€éº¼é€éå»', 'è˜‡æ•¬èˆœã€0937365683ã€å°å—å¸‚å–„åŒ–å€ä¸­èˆˆè·¯117è™Ÿ', 'æ©', 'Zenfone5', 'é‚£ç¶­ä¿®ä¸€æ¬¡è¢å¹•è¦å¤šå°‘', 'è«‹å•ä¸€ä¸‹å®˜ç¶²è²·çš„ä¿æ•…æ˜¯å¤šä¹…', 'æ‰‹æ©Ÿé›»åŸéµæ‹–è½ã€è¢å¹•ç„¡æ³•é¡¯ç¤ºç„¡æ³•è™•æ§', 'å¥½', 'æˆ‘çš„sn:E9AZCY162071', 'å¥½çš„', 'å¯ä»¥æŒ‡å®šåœ°æ–¹å—', 'å¥½', 'å®˜ç¶²', 'å°', 'ç¶­ä¿®å¤§ç´„è¦å¤šä¹…']\n",
      "['å“ªæˆ‘è«‹å•ä¸€ä¸‹å–”  å› ç‚ºæˆ‘æ˜¨å¤©æƒæ¯’é€™å€‹ç¨‹å¼éƒ½æœƒåœåœ¨80% 83% 95% é€™å€‹æ˜¯ä»€éº¼å•é¡Œå•Šï¼Ÿ', 'å—¯å—¯ å•†åº—ä¸‹è¼‰ã„‰', 'æ²’æœ‰äº† è¬è¬ æœ‰éœ€è¦ æˆ‘æœƒåœ¨å•ã„‰', 'è¬è¬å¦³ è¾›è‹¦äº† å†è¦‹:)^^', 'æˆ‘æŒ‰æ»¿æ„ :)  ^^  ', 'æ“ä½œï¼Ÿ', 'é‚£å€‹æˆ‘æƒ³è«‹å•ä¸€ä¸‹DIYå¤§å¸«é€™å€‹ç¨‹å¼æœƒä¸æœƒè·Ÿæ‰‹æ©Ÿç³»çµ±ç¨‹å¼ä¸åˆç„¶å¾Œé€ æˆç¨‹å¼ç•¶æ©Ÿï¼Ÿ', 'ç‚ºä»€éº¼é€™å€‹ç¨‹æ¯æ¬¡æƒæ¯’éƒ½åœåœ¨80% ä¸ç„¶å°±æ˜¯83% 95%å‘¢ï¼Ÿ', 'å¦³å¥½', 'ä¸å¥½æ„æ€æˆ‘æƒ³è«‹å•ä¸€ä¸‹', 'å¥½ ç­‰æˆ‘ä¸€ä¸‹å–”', 'å¯æ˜¯æ‰‹æ©Ÿå¸¸å¸¸é‡æ–°é–‹æ©Ÿæœƒä¸æœƒå½±éŸ¿æ‰‹æ©Ÿçš„ç¨‹å¼ä»¥åŠå£½å‘½ï¼Ÿ', 'Zenfone2', 'æ˜¯èªªæƒæ¯’å—ï¼Ÿ', 'å¯ä»¥äº†:)', 'å¤ªä¹…æ²’é‡é–‹æ©Ÿï¼Ÿ  æ„æ€æ˜¯èªª æ‰‹æ©Ÿéä¸€æ®µæ™‚é–“è¦é‡èª²é–‹çš„æ„æ€ï¼Ÿ', 'å¥½ æˆ‘çŸ¥é“äº† è¬è¬å–” ^^', 'æ˜¯å› ç‚ºç¨‹å¼å¤ªå¤šå—ï¼Ÿ', 'å‰›å‰›ä¸Šä¸€å€‹å®¢æœå«æˆ‘æŠŠå…¨éƒ¨ç¨‹å¼å¿«å–æ¸…æ¥šæˆ‘å·²ç¶“ç”¨äº† ç¾åœ¨è¦æ€éº¼è¾¦ï¼Ÿ', 'æ©å¥½ æˆ‘çŸ¥é“äº†  è¬è¬å¦³:)  ^^', ':) ^^']\n",
      "['æˆ‘è¦å•çš„æ˜¯,å¹³å¸¸çš„è®Šå£“å™¨å¤šæ•¸ç‚º1a /2a', 'å¥½çš„', 'ä½ å¥½,', 'æˆ‘ä¸Šé¢çš„å•é¡Œ,è«‹å•æ‚¨çœ‹å¾—åˆ°å—', 'æˆ‘çŸ¥é“Asusè²·æ‰‹æ©Ÿé™„é€çš„è®Šå£“å™¨,æ˜¯è¼¸å‡º1.5A', 'è¬è¬æ‚¨çš„å›ç­”', 'æˆ‘çŸ¥é“ã€‚ç•¶ç„¶æ¯å€‹å» å•†éƒ½æœƒå»ºè­°ç”¨åŸå» çš„', 'æˆ‘æƒ³è«‹å•,æˆ‘å¯ä¸å¯ä»¥ä½¿ç”¨è®Šå£“å™¨2A çš„éƒ¨åˆ†ç‚ºæ‰‹æ©Ÿå……é›»å‘¢ï¼Ÿ', 'æˆ‘çš„æ‰‹æ©Ÿæ˜¯zenfone6']\n",
      "['è¬è¬', 'æ‚¨å¥½ è«‹å•é«˜é›„å“ªè£¡æœ‰å±•ç¤ºZenFone 3å‘¢', 'æ²’æœ‰äº†', 'å—¯å—¯ å¥½ ']\n",
      "['ä½ å¥½æˆ‘å•Ÿå‹•å®‰å…¨å¾Œ', 'å“ˆå›‰ï¼Ÿ', 'å¥½çš„', 'é‚„æ˜¯æ‰“ä¸é–‹å…§é¡', 'å¯æ˜¯æˆ‘éä¿å›ºå…©å€‹æœˆäº†', 'é€™æ¨£å¦‚æœç¶­ä¿®é¡é ­è²»ç”¨å¤§æ¦‚æœƒå¤šå°‘', 'è¬è¬', 'æ‰€ä»¥æ²’æœ‰è¾¦æ³•çŸ¥é“æ›é¡çš„å¤§æ¦‚å ±åƒ¹å—ï¼Ÿ']\n",
      "['é€”ä¸­çªç„¶ä¸èƒ½å‹•,è¢å¹•èƒŒæ™¯è®Šæˆé»‘è‰²', 'æˆ‘æœ‰å®šæœŸæª¢æŸ¥æ˜¯å¦æœ‰æ›´æ–°', 'ä¸å¥½æ„æ€å‰›å‰›æ‰“éŒ¯ç¶²å€äº†', 'é‡é–‹æ©Ÿæ™‚æœƒä¸€ç›´éœ‡å‹•', 'ä¹‹å¾Œæ‰èƒ½æ­£å¸¸é–‹æ©Ÿ', 'é€™æ¨£æ˜¯è©²å¦‚ä½•è™•ç†', 'æœ‰', 'ä¸å¥½æ„æ€æˆ‘ä¸å¤ªçŸ¥é“åœ¨å“ªè£¡', 'è«‹å•åœ¨ä½¿ç”¨æ‰‹æ©Ÿæ™‚', 'ä¹‹å¾Œéäº†ä¸€æœƒå…’å…¨æš—äº†', 'éƒ½ä¸èƒ½å‹•', 'zenfone 5', 'è¦å»å“ªè£¡æ›´æ–°', 'å°æ‡‰ç‰ˆæœ¬', '.78?']\n",
      "['å•Šç¾…å“ˆ,å‚‘å¤«', 'å–”,å¥½,', 'æˆ‘æƒ³å•,é™¤äº†ç¶²è·¯å•†åº—å“ªè£¡å¯ä»¥è²·åˆ°å¯¦é«”åŸå» å……é›»ç·š', 'z5', 'å–”,å¥½å§,é‚£ä¹‹å¾Œæœƒæœ‰å—', 'å¥½çš„', 'åªæœ‰1å°æ™‚å¿«ä¿®,éœ€è¦æ‹¿åˆ°çš‡å®¶ç¾å ´å—', 'è«‹å•æœ‰åŸå» å¿«é€Ÿå……é›»å—', 'åªæœ‰ä¸€çµ„ ç·š+å……é›»å™¨å—,é‚„æ˜¯æœ‰åˆ†é–‹å–®å”®', 'æœ‰åƒ¹éŒ¢å—']\n",
      "['æˆ‘æƒ³çŸ¥é“ASUS ZenFone 3 (ZE552KL)ç›®å‰è³¼è²·æœ‰ä½•å„ªæƒ ', 'æˆ‘æƒ³çŸ¥é“ASUS ZenFone 3 (ZE552KL)ç›®å‰è³¼è²·æœ‰ä½•å„ªæƒ ']\n",
      "['å¦å¤–å•å–®æ›²æœ€é•·èƒ½æ”¾å¤šä¹…?', 'å–®æ›²ç„¡é™åˆ¶?', '1600msæ˜¯å¤šä¹?', 'éŸ³æ¨‚æ’­æ”¾æ™‚é–“']\n",
      "['å¥½çš„è¬è¬æ‚¨ğŸ˜†', 'è«‹å•è¦æ€éº¼é—œé–‰zenlife']\n",
      "['åªè¦ä¸‰å››å€‹å½±ç‰‡å°±ç•¶,ç‚ºä½•ç”¨è˜‹æœ4ä¸æœƒè²´å…¬å¸æ‰‹æ©Ÿæ‰ç™¼ç”Ÿ,æ‰€ä»¥æƒ³äº†è§£,æ‡‰è©²è·Ÿlineç„¡é—œå§ï¼', 'é‚£äº›è³‡è¨Š', 'lineå‚³æ‹å½±ç‰‡', 'æåœ‹æ…¶,0928284789 kuoching86841478@yahoo.com.twä½•è¬‚æ©Ÿå°,æ¿æœ¬', 'æ„Ÿè¬', 'é›²ç«¯çš„æª”æ¡ˆä¸‹è¼‰æ˜¯å¦æœƒæ¯”è¼ƒæ…¢,æˆ‘æœ‰å…©å€‹é›²ç«¯ç¡¬ç¢Ÿè¯ç¢©,åŠGoogle+ã€‚å¾ˆä¹…å°±åæ‡‰,è¦ºå¾—æ˜¯å¦é‹ç®—é€Ÿåº¦ä¸å¤ ', 'æ‰‹æ©Ÿæ‰è²·åŠå¹´,å®¢æœåŠæ™‚é€š', 'æˆ‘å¸Œæœ›æ”¯æŒåœ‹è²¨,æ‰å¸Œæœ›èƒ½æ‰¾å‡ºæ¯›ç—…å‡ºåœ¨é‚£,', 'ä¸åœ¨æ—é‚Šè¦æ‰¾ ä¸‹æ¬¡å¦‚ä½•è¯çµ¡', 'ZenFone2', 'ä»¥å‰ç”¨è˜‹æœä¸æœƒ,æ‡‰è©²æ²’æœ‰ã€‚å¯ä»¥å¹«æˆ‘æŸ¥', 'æ€éº¼æ‰¾', 'ç‚ºä½•ä¸Šå‚³å¤šå¼µå½±ç‰‡,æœƒè¦é‡æ–°å‚³,å·²ç¶“åæ‡‰å¤šæ¬¡,é‚„æ˜¯ç„¡è§£ã€‚', 'ä¸Šå‚³å¤ªä¹…å°±è¦é‡ä¾†  551', 'æ˜¯å¦é€™å€‹', 'æ„Ÿè¬,æ°æ°']\n",
      "['é€™å•é¡Œå“ªæ™‚æœƒè§£æ±º', 'å‡ç´šç‚º6.0.1å¾Œ,å¦‚ä½•æŠŠæ‡‰ç”¨å‘ˆå¼ç§»åˆ°SDå¡å…§', 'é‚£è¦å¦‚ä½•è™•ç†', 'é‚„æœ‰å…¶ä»–è¾¦æ³•å¯ç§»å—']\n",
      "['è«‹å•å°ä¸­å¸‚æœ‰ç›´ç‡Ÿæœå‹™ç«™å—ï¼Ÿ', 'å—¯', 'æ²’æœ‰,æˆ‘è‡ªè¡Œéå»è¬è¬']\n",
      "['æˆ‘çš„zenfone2æœƒæœ‰é–ƒå±çš„ç‹€æ³', 'é‚£è©²æ€éº¼ç¢ºå®šè‡ªå·±çš„æ‰‹æ©Ÿé‚„åœ¨ä¿å›ºå…§å‘¢', 'é¢æ¿çš„ç•«é¢æœƒé–ƒçˆ,æœ‰æ™‚é‚„æœ‰åœåœ¨ç‰¹å®šç•«é¢çš„ç‹€æ³', 'æ‚¨å¥½,æˆ‘æœ‰æ‰‹æ©Ÿæ–¹é¢çš„å•é¡Œ', 'å¥½çš„,è¬è¬æ‚¨~']\n"
     ]
    }
   ],
   "source": [
    "for index, row in enumerate(pos_data_sets):\n",
    "    if index>20:\n",
    "        break\n",
    "    print(pos_data_sets[row])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16270"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "8135*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = []\n",
    "satisfied_degree = []\n",
    "for index, key in enumerate(pos_data_sets):\n",
    "#     if index>16270:\n",
    "#         break\n",
    "    corpus.append(' '.join(jieba.cut(' '.join(pos_data_sets[key]), cut_all=False)))\n",
    "    satisfied_degree.append(1)\n",
    "\n",
    "for key in neg_data_sets:\n",
    "    corpus.append(' '.join(jieba.cut(' '.join(neg_data_sets[key]), cut_all=False)))\n",
    "    satisfied_degree.append(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24406"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.å…ˆå°‡æ­£é¢èˆ‡è² é¢çš„ ä½¿ç”¨è€…å­—è© åˆ©ç”¨TFIDF ç®—å‡ºBag of word\n",
    "## 2.å†å°‡æ­£è² é¢ä¸Ÿå»Train Classier \n",
    "## 3.åœ¨è·ŸåŠ©æ•™çµ¦çš„æƒ…ç·’LIB æ¯”å°åˆ†æ•¸çœ‹çœ‹\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import plotly.graph_objs as go\n",
    "from plotly.graph_objs import *\n",
    "import plotly.plotly as py\n",
    "import plotly.figure_factory as ff\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "np_corpus = np.array(corpus)\n",
    "np_satisfied_degree = np.array(satisfied_degree)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    np_corpus, np_satisfied_degree, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# scikit-learn example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating the bag of words...\n",
      "\n",
      "(17084, 500)\n",
      "(7322, 500)\n"
     ]
    }
   ],
   "source": [
    "print(\"Creating the bag of words...\\n\")\n",
    "\n",
    "# Initialize the \"CountVectorizer\" object, which is scikit-learn's\n",
    "# bag of words tool.  \n",
    "vectorizer = CountVectorizer(analyzer = \"word\",   \\\n",
    "                             tokenizer = None,    \\\n",
    "                             preprocessor = None, \\\n",
    "                             stop_words = None,   \\\n",
    "                             max_features = 500) \n",
    "\n",
    "# fit_transform() does two functions: First, it fits the model\n",
    "# and learns the vocabulary; second, it transforms our training data\n",
    "# into feature vectors. The input to fit_transform should be a list of \n",
    "# strings.\n",
    "train_data_features = vectorizer.fit_transform(X_train)\n",
    "test_data_features = vectorizer.transform(X_test)\n",
    "\n",
    "print(train_data_features.shape)\n",
    "print(test_data_features.shape)\n",
    "\n",
    "# Numpy arrays are easy to work with, so convert the result to an \n",
    "# array\n",
    "train_data_features = train_data_features.toarray()\n",
    "test_data_features = test_data_features.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyze = vectorizer.build_analyzer()\n",
    "analyze(\"è¯ç¢© å“è³ª å¥½å·®\")\n",
    "len(train_data_features[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17084, 300)\n",
      "(7322, 300)\n"
     ]
    }
   ],
   "source": [
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(train_data_features)\n",
    "print(X_train_tfidf.shape)\n",
    "X_test_tfidf = tfidf_transformer.transform(test_data_features)\n",
    "print(X_test_tfidf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.81      0.15      0.25      2390\n",
      "          1       0.70      0.98      0.82      4932\n",
      "\n",
      "avg / total       0.74      0.71      0.63      7322\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Naive_bayes \n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB().fit(X_train_tfidf, y_train)\n",
    "\n",
    "predicted = clf.predict(X_test_tfidf)\n",
    "\n",
    "print(metrics.classification_report(y_test, predicted, target_names=['0', '1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the SVM...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.66      0.65      0.65      2390\n",
      "          1       0.83      0.84      0.83      4932\n",
      "\n",
      "avg / total       0.77      0.78      0.77      7322\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SVM\n",
    "print(\"Training the SVM...\")\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
    "\n",
    "clf = LinearSVC().fit(X_train_tfidf, y_train)\n",
    "predicted = clf.predict(X_test_tfidf)\n",
    "print(metrics.classification_report(y_test, predicted, target_names=['0', '1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the DecisionTree...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.61      0.78      0.68      2390\n",
      "          1       0.88      0.76      0.81      4932\n",
      "\n",
      "avg / total       0.79      0.77      0.77      7322\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Training the DecisionTree...\")\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# criterion : impurity function\n",
    "# max_depth : maximum depth of tree\n",
    "# random_state : seed of random number generator\n",
    "tree = DecisionTreeClassifier(criterion='entropy', \n",
    "                              max_depth=3, \n",
    "                              random_state=0)\n",
    "tree.fit(X_train_tfidf, y_train)\n",
    "predicted = tree.predict(X_test_tfidf)\n",
    "print(metrics.classification_report(y_test, predicted, target_names=['0', '1']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the random forest...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.65      0.66      2390\n",
      "          1       0.83      0.84      0.84      4932\n",
      "\n",
      "avg / total       0.78      0.78      0.78      7322\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Training the random forest...\")\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Initialize a Random Forest classifier with 100 trees\n",
    "forest = RandomForestClassifier(n_estimators = 100) \n",
    "\n",
    "# Fit the forest to the training set, using the bag of words as \n",
    "# features and the sentiment labels as the response variable\n",
    "#\n",
    "# This may take a few minutes to run\n",
    "forest = forest.fit( X_train_tfidf,  y_train)\n",
    "\n",
    "predicted = forest.predict(X_test_tfidf)\n",
    "\n",
    "print(metrics.classification_report(y_test, predicted, target_names=['0', '1']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manually Playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_data = [['çˆ›å…¬å¸ è¯ç¢© å“è³ª ç„¡æ³• è§£æ±º å•é¡Œ'], ['é€™å…¬å¸ å¥½çˆ› æƒ¹æˆ‘ç”Ÿæ°£ ç…©æ¬¸ å¹¹ ç„¡æ³• è§£æ±º å•é¡Œ'], ['ä¸çŸ¥æ€éº¼è¨­å®š', 'ZF2', 'æ»¿æ„,è¬è¬ä½ ', 'æ‰èƒ½æ”¶åˆ°', 'å°±æ˜¯MMSæ²’æœ‰åœ–ç‰‡', 'æ–‡å­—æ”¶åˆ°', 'é‚„æ˜¯è¦,æ”¾åœ¨å¡1', 'åŸä¾†å¦‚æ­¤', 'æ”¾åˆ°sim1', 'ä¹‹å‰ç”¨S3,å¯ä»¥æ”¶åˆ°mms', 'æ‡‰è©²ä¸æ˜¯ä¸­è¯é›»ä¿¡çš„å•é¡Œ', 'æ‰èƒ½æ”¶åˆ°'],\n",
    "['é‚£ä¸€å€‹å°æ™‚é ç´„å¿«ä¿® çš„éƒ¨åˆ†æ˜¯?', 'é€™æ¨£è¦æ€éº¼è™•ç†å‘¢', 'æ‰€ä»¥å°±æœ‰æ©Ÿæœƒ ç•¶æ—¥ç¶­ä¿®å¥½å›‰', 'åŠæœ€ä¸‹é¢ä¸‰å€‹ æ¡ˆä»¶  ä¹Ÿæ²’åæ‡‰', 'ZF2', 'ä¸€å€‹å°æ™‚å¿«ä¿®çš„éƒ¨åˆ†', ' æ©æ©  å°', 'ä¸æ˜¯', 'å¦‚æœé€ä¿®çš„è©± æœ‰å¯èƒ½ç•¶å¤©å°±å¥½å—', 'è«‹å•è¢å¹•è§¸æ§æŒ‰äº†æ²’åæ‡‰', 'æ²’ä½¿ç”¨å–®æ‰‹æ¨¡å¼ä¸‹   ä»»ä½•æƒ…æ³é‚£ä¸‰å€‹æŒ‰éµéƒ½æ²’åæ‡‰', 'é‚„æœ‰è¢å¹•ä¸­é–“éƒ¨åˆ†å€å¡ŠæŒ‰äº†ä¹Ÿæ²’åæ‡‰', 'æ©   å¥½   æˆ‘äº†è§£äº†', 'è¬è¬ä½ ', '550ML', 'ç¾åœ¨æˆ‘åªèƒ½è½‰æ›æˆå–®æ‰‹æ“ä½œè®Šæˆå°è¢å¹•çš„è™›æ“¬ä¸‰å€‹è§¸æ§æŒ‰éˆ•æ‰èƒ½ä½¿ç”¨é‚£ä¸‰å€‹æ¡ˆä»¶çš„åŠŸèƒ½', 'æ˜¯å› ç‚ºæ²’è¾¦æ³•æŒ‰ æˆ‘æ‰è½‰æ›æˆå–®æ‰‹æ¨¡å¼çš„'],\n",
    "['ç¶­ä¿®åœ°é»æ˜¯æ¿æ©‹çš‡å®¶æ²’éŒ¯', 'ç­è§£, æ„Ÿè¬æ‚¨~~~', 'æ‚¨å¥½,è«‹å•å®˜ç¶²ä¸Šçš„ç¶­ä¿®é€²åº¦æŸ¥è©¢ å¦‚æœé¡¯ç¤ºå¯ä»¥å»å–ä»¶äº† æ˜¯å¦å°±è¡¨ç¤ºç¶­ä¿®å®Œæˆäº†å‘¢ï¼Ÿ', 'å› ç‚ºä¹‹å‰éƒ½æœƒæœ‰ç°¡è¨Šé€šçŸ¥ ä½†æˆ‘ä¸€ç›´æ²’æ”¶åˆ° å‰›å‰›ç·šä¸ŠæŸ¥è©¢äº† ç™¼ç¾æ˜¨å¤©å°±å¯ä»¥å–ä»¶äº†', 'æ±Ÿé¸å¸†', 'TWA3610915'],\n",
    "['ZENFONE 2', 'ä½ å¥½ å¯ä»¥ç·šä¸ŠæŸ¥è©¢ä¿å›ºæ—¥æœŸå—', 'F5AZFG21A099', 'å¥½çš„ è¬è¬'],\n",
    "['å·²å‚³è¼¸åˆ°sdå¡äº†', 'æª”æ¡ˆè¦æ”¾åˆ°é‚£è£¡?', 'æˆ‘å…ˆè©¦è©¦,æœ‰å•é¡Œå†ä¾†è«‹å•æ‚¨å€‘', 'tks', 'å¦‚å·²æœ‰è§£å£“æœƒæœ‰ä»€éº¼ç‹€æ³å—ï¼Ÿ', 'è«‹å•è¦å¦‚ä½•æ‰‹å‹•æ›´æ–°ä¸‹è¼‰è»”é«”?', 'æˆ‘çš„æ‰‹æ©Ÿæ˜¯ ZenFone6', 'sdå¡å¯ä»¥?', 'é€™è£¡å°å—ï¼Ÿ', 'å·²è§£å£“ç¸®æª”è¦ç§»é™¤å—ï¼Ÿ', 'ok '],\n",
    "['ä½ å¥½', 'æˆ‘è¦æŠŠç›®å‰ä½¿ç”¨çš„æ‰‹æ©Ÿè™Ÿç¢¼è½‰åˆ°å¦å¤–ä¸€æ”¯,å‡ºé–€ä¸ç”¨å¸¶äºŒæ”¯', 'ç°¡å–®æ˜ç­', 'æˆ‘è¦å°‡æ‰‹æ©Ÿè½‰æ¥,æ”¶åˆ°éŒ¯èª¤è¨Šæ¯,ä¸èƒ½è½‰æ¥å‡ºå»', 'ç°¡å–®èªªæˆ‘è¦å°‡æˆ‘çš„æ‰‹æ©Ÿè™Ÿç¢¼è½‰è‡³å¦ä¸€æ”¯', 'æˆ‘æœ‰é–‹ç¶²è·¯', 'zf3', 'æŠŠæˆ‘çš„é›»è©±è½‰åˆ°å¦å¤–ä¸€æ”¯', 'äºŒæ”¯æ‰‹æ©Ÿ', 'ä½†ä¸è¡Œ', 'è¬äº†,äº†è§£', 'ä¸èƒ½è½‰æ¥åˆ°å¦ä¸€æ”¯æ‰‹æ©Ÿ', 'ä¾†é›»è½‰æ¥ç„¡æ³•è½‰æ¥', '886', 'ç¶²è·¯å‚³å›éé æœŸå›æ‡‰', 'é€šè©±è¨­å®š==>ä¾†é›»è½‰æ¥==>ä¸€å¾‹è½‰æ¥==>è¼¸å…¥è™Ÿç¢¼å¾ŒæŒ‰é–‹å•Ÿ,å‡ºç¾ç¶²è·¯å‚³å›éé æœŸå›æ‡‰'],\n",
    "['è¬è¬æ‚¨', 'è«‹å•ä¸€ä¸‹', 'zenfone2 4G/32Gç‰ˆçš„å¯ä»¥å»å¤§é™¸ä½¿ç”¨é€šè©±åŠŸèƒ½å—ï¼Ÿ', 'å› å®˜æ–¹çš„è«–å£‡æ˜¯æœ‰èªªä¸èƒ½ä½¿ç”¨4Gä¸Šç¶²,ä½†æˆ‘ä¸æ¸…æ¥šæ˜¯å¦å¯ä»¥ä½¿ç”¨2Gæˆ–3GåŠŸèƒ½ï¼Ÿ', 'è¬è¬æ‚¨', 'å¥½', 'å¥½çš„'],\n",
    "['æˆ‘çš„è¢å¹•è®Šé€™æ¨£', 'è¦æ€éº¼é€ä¿®', 'å¥½çš„', 'é‚£è¦æ€éº¼çœ‹snåºè™Ÿ', 'ä¿å›ºæœ‰å…è²»ç¶­ä¿®å—', 'æ©', 'é»‘ç™½çš„', 'é‚£è¦æ€éº¼é€éå»', 'è˜‡æ•¬èˆœã€0937365683ã€å°å—å¸‚å–„åŒ–å€ä¸­èˆˆè·¯117è™Ÿ', 'æ©', 'Zenfone5', 'é‚£ç¶­ä¿®ä¸€æ¬¡è¢å¹•è¦å¤šå°‘', 'è«‹å•ä¸€ä¸‹å®˜ç¶²è²·çš„ä¿æ•…æ˜¯å¤šä¹…', 'æ‰‹æ©Ÿé›»åŸéµæ‹–è½ã€è¢å¹•ç„¡æ³•é¡¯ç¤ºç„¡æ³•è™•æ§', 'å¥½', 'æˆ‘çš„sn:E9AZCY162071', 'å¥½çš„', 'å¯ä»¥æŒ‡å®šåœ°æ–¹å—', 'å¥½', 'å®˜ç¶²', 'å°', 'ç¶­ä¿®å¤§ç´„è¦å¤šä¹…'],\n",
    "['å“ªæˆ‘è«‹å•ä¸€ä¸‹å–”  å› ç‚ºæˆ‘æ˜¨å¤©æƒæ¯’é€™å€‹ç¨‹å¼éƒ½æœƒåœåœ¨80% 83% 95% é€™å€‹æ˜¯ä»€éº¼å•é¡Œå•Šï¼Ÿ', 'å—¯å—¯ å•†åº—ä¸‹è¼‰ã„‰', 'æ²’æœ‰äº† è¬è¬ æœ‰éœ€è¦ æˆ‘æœƒåœ¨å•ã„‰', 'è¬è¬å¦³ è¾›è‹¦äº† å†è¦‹:)^^', 'æˆ‘æŒ‰æ»¿æ„ :)  ^^  ', 'æ“ä½œï¼Ÿ', 'é‚£å€‹æˆ‘æƒ³è«‹å•ä¸€ä¸‹DIYå¤§å¸«é€™å€‹ç¨‹å¼æœƒä¸æœƒè·Ÿæ‰‹æ©Ÿç³»çµ±ç¨‹å¼ä¸åˆç„¶å¾Œé€ æˆç¨‹å¼ç•¶æ©Ÿï¼Ÿ', 'ç‚ºä»€éº¼é€™å€‹ç¨‹æ¯æ¬¡æƒæ¯’éƒ½åœåœ¨80% ä¸ç„¶å°±æ˜¯83% 95%å‘¢ï¼Ÿ', 'å¦³å¥½', 'ä¸å¥½æ„æ€æˆ‘æƒ³è«‹å•ä¸€ä¸‹', 'å¥½ ç­‰æˆ‘ä¸€ä¸‹å–”', 'å¯æ˜¯æ‰‹æ©Ÿå¸¸å¸¸é‡æ–°é–‹æ©Ÿæœƒä¸æœƒå½±éŸ¿æ‰‹æ©Ÿçš„ç¨‹å¼ä»¥åŠå£½å‘½ï¼Ÿ', 'Zenfone2', 'æ˜¯èªªæƒæ¯’å—ï¼Ÿ', 'å¯ä»¥äº†:)', 'å¤ªä¹…æ²’é‡é–‹æ©Ÿï¼Ÿ  æ„æ€æ˜¯èªª æ‰‹æ©Ÿéä¸€æ®µæ™‚é–“è¦é‡èª²é–‹çš„æ„æ€ï¼Ÿ', 'å¥½ æˆ‘çŸ¥é“äº† è¬è¬å–” ^^', 'æ˜¯å› ç‚ºç¨‹å¼å¤ªå¤šå—ï¼Ÿ', 'å‰›å‰›ä¸Šä¸€å€‹å®¢æœå«æˆ‘æŠŠå…¨éƒ¨ç¨‹å¼å¿«å–æ¸…æ¥šæˆ‘å·²ç¶“ç”¨äº† ç¾åœ¨è¦æ€éº¼è¾¦ï¼Ÿ', 'æ©å¥½ æˆ‘çŸ¥é“äº†  è¬è¬å¦³:)  ^^', ':) ^^'],\n",
    "['æˆ‘è¦å•çš„æ˜¯,å¹³å¸¸çš„è®Šå£“å™¨å¤šæ•¸ç‚º1a /2a', 'å¥½çš„', 'ä½ å¥½,', 'æˆ‘ä¸Šé¢çš„å•é¡Œ,è«‹å•æ‚¨çœ‹å¾—åˆ°å—', 'æˆ‘çŸ¥é“Asusè²·æ‰‹æ©Ÿé™„é€çš„è®Šå£“å™¨,æ˜¯è¼¸å‡º1.5A', 'è¬è¬æ‚¨çš„å›ç­”', 'æˆ‘çŸ¥é“ã€‚ç•¶ç„¶æ¯å€‹å» å•†éƒ½æœƒå»ºè­°ç”¨åŸå» çš„', 'æˆ‘æƒ³è«‹å•,æˆ‘å¯ä¸å¯ä»¥ä½¿ç”¨è®Šå£“å™¨2A çš„éƒ¨åˆ†ç‚ºæ‰‹æ©Ÿå……é›»å‘¢ï¼Ÿ', 'æˆ‘çš„æ‰‹æ©Ÿæ˜¯zenfone6'],\n",
    "['è¬è¬', 'æ‚¨å¥½ è«‹å•é«˜é›„å“ªè£¡æœ‰å±•ç¤ºZenFone 3å‘¢', 'æ²’æœ‰äº†', 'å—¯å—¯ å¥½ '],\n",
    "['ä½ å¥½æˆ‘å•Ÿå‹•å®‰å…¨å¾Œ', 'å“ˆå›‰ï¼Ÿ', 'å¥½çš„', 'é‚„æ˜¯æ‰“ä¸é–‹å…§é¡', 'å¯æ˜¯æˆ‘éä¿å›ºå…©å€‹æœˆäº†', 'é€™æ¨£å¦‚æœç¶­ä¿®é¡é ­è²»ç”¨å¤§æ¦‚æœƒå¤šå°‘', 'è¬è¬', 'æ‰€ä»¥æ²’æœ‰è¾¦æ³•çŸ¥é“æ›é¡çš„å¤§æ¦‚å ±åƒ¹å—ï¼Ÿ'],\n",
    "['é€”ä¸­çªç„¶ä¸èƒ½å‹•,è¢å¹•èƒŒæ™¯è®Šæˆé»‘è‰²', 'æˆ‘æœ‰å®šæœŸæª¢æŸ¥æ˜¯å¦æœ‰æ›´æ–°', 'ä¸å¥½æ„æ€å‰›å‰›æ‰“éŒ¯ç¶²å€äº†', 'é‡é–‹æ©Ÿæ™‚æœƒä¸€ç›´éœ‡å‹•', 'ä¹‹å¾Œæ‰èƒ½æ­£å¸¸é–‹æ©Ÿ', 'é€™æ¨£æ˜¯è©²å¦‚ä½•è™•ç†', 'æœ‰', 'ä¸å¥½æ„æ€æˆ‘ä¸å¤ªçŸ¥é“åœ¨å“ªè£¡', 'è«‹å•åœ¨ä½¿ç”¨æ‰‹æ©Ÿæ™‚', 'ä¹‹å¾Œéäº†ä¸€æœƒå…’å…¨æš—äº†', 'éƒ½ä¸èƒ½å‹•', 'zenfone 5', 'è¦å»å“ªè£¡æ›´æ–°', 'å°æ‡‰ç‰ˆæœ¬', '.78?'],\n",
    "['å•Šç¾…å“ˆ,å‚‘å¤«', 'å–”,å¥½,', 'æˆ‘æƒ³å•,é™¤äº†ç¶²è·¯å•†åº—å“ªè£¡å¯ä»¥è²·åˆ°å¯¦é«”åŸå» å……é›»ç·š', 'z5', 'å–”,å¥½å§,é‚£ä¹‹å¾Œæœƒæœ‰å—', 'å¥½çš„', 'åªæœ‰1å°æ™‚å¿«ä¿®,éœ€è¦æ‹¿åˆ°çš‡å®¶ç¾å ´å—', 'è«‹å•æœ‰åŸå» å¿«é€Ÿå……é›»å—', 'åªæœ‰ä¸€çµ„ ç·š+å……é›»å™¨å—,é‚„æ˜¯æœ‰åˆ†é–‹å–®å”®', 'æœ‰åƒ¹éŒ¢å—'],\n",
    "['æˆ‘æƒ³çŸ¥é“ASUS ZenFone 3 (ZE552KL)ç›®å‰è³¼è²·æœ‰ä½•å„ªæƒ ', 'æˆ‘æƒ³çŸ¥é“ASUS ZenFone 3 (ZE552KL)ç›®å‰è³¼è²·æœ‰ä½•å„ªæƒ '],\n",
    "['å¦å¤–å•å–®æ›²æœ€é•·èƒ½æ”¾å¤šä¹…?', 'å–®æ›²ç„¡é™åˆ¶?', '1600msæ˜¯å¤šä¹?', 'éŸ³æ¨‚æ’­æ”¾æ™‚é–“'],\n",
    "['å¥½çš„è¬è¬æ‚¨ğŸ˜†', 'è«‹å•è¦æ€éº¼é—œé–‰zenlife'],\n",
    "['åªè¦ä¸‰å››å€‹å½±ç‰‡å°±ç•¶,ç‚ºä½•ç”¨è˜‹æœ4ä¸æœƒè²´å…¬å¸æ‰‹æ©Ÿæ‰ç™¼ç”Ÿ,æ‰€ä»¥æƒ³äº†è§£,æ‡‰è©²è·Ÿlineç„¡é—œå§ï¼', 'é‚£äº›è³‡è¨Š', 'lineå‚³æ‹å½±ç‰‡', 'æåœ‹æ…¶,0928284789 kuoching86841478@yahoo.com.twä½•è¬‚æ©Ÿå°,æ¿æœ¬', 'æ„Ÿè¬', 'é›²ç«¯çš„æª”æ¡ˆä¸‹è¼‰æ˜¯å¦æœƒæ¯”è¼ƒæ…¢,æˆ‘æœ‰å…©å€‹é›²ç«¯ç¡¬ç¢Ÿè¯ç¢©,åŠGoogle+ã€‚å¾ˆä¹…å°±åæ‡‰,è¦ºå¾—æ˜¯å¦é‹ç®—é€Ÿåº¦ä¸å¤ ', 'æ‰‹æ©Ÿæ‰è²·åŠå¹´,å®¢æœåŠæ™‚é€š', 'æˆ‘å¸Œæœ›æ”¯æŒåœ‹è²¨,æ‰å¸Œæœ›èƒ½æ‰¾å‡ºæ¯›ç—…å‡ºåœ¨é‚£,', 'ä¸åœ¨æ—é‚Šè¦æ‰¾ ä¸‹æ¬¡å¦‚ä½•è¯çµ¡', 'ZenFone2', 'ä»¥å‰ç”¨è˜‹æœä¸æœƒ,æ‡‰è©²æ²’æœ‰ã€‚å¯ä»¥å¹«æˆ‘æŸ¥', 'æ€éº¼æ‰¾', 'ç‚ºä½•ä¸Šå‚³å¤šå¼µå½±ç‰‡,æœƒè¦é‡æ–°å‚³,å·²ç¶“åæ‡‰å¤šæ¬¡,é‚„æ˜¯ç„¡è§£ã€‚', 'ä¸Šå‚³å¤ªä¹…å°±è¦é‡ä¾†  551', 'æ˜¯å¦é€™å€‹', 'æ„Ÿè¬,æ°æ°'],\n",
    "['é€™å•é¡Œå“ªæ™‚æœƒè§£æ±º', 'å‡ç´šç‚º6.0.1å¾Œ,å¦‚ä½•æŠŠæ‡‰ç”¨å‘ˆå¼ç§»åˆ°SDå¡å…§', 'é‚£è¦å¦‚ä½•è™•ç†', 'é‚„æœ‰å…¶ä»–è¾¦æ³•å¯ç§»å—'],\n",
    "['è«‹å•å°ä¸­å¸‚æœ‰ç›´ç‡Ÿæœå‹™ç«™å—ï¼Ÿ', 'å—¯', 'æ²’æœ‰,æˆ‘è‡ªè¡Œéå»è¬è¬'],\n",
    "['æˆ‘çš„zenfone2æœƒæœ‰é–ƒå±çš„ç‹€æ³', 'é‚£è©²æ€éº¼ç¢ºå®šè‡ªå·±çš„æ‰‹æ©Ÿé‚„åœ¨ä¿å›ºå…§å‘¢', 'é¢æ¿çš„ç•«é¢æœƒé–ƒçˆ,æœ‰æ™‚é‚„æœ‰åœåœ¨ç‰¹å®šç•«é¢çš„ç‹€æ³', 'æ‚¨å¥½,æˆ‘æœ‰æ‰‹æ©Ÿæ–¹é¢çš„å•é¡Œ', 'å¥½çš„,è¬è¬æ‚¨~']]\n",
    "test_data_X = []\n",
    "for data in test_data:\n",
    "    test_data_X.append(' '.join(jieba.cut(' '.join(data), cut_all=False)))\n",
    "test_data_Y = np.ones(21)\n",
    "test_data_Y = np.append([-1, -1], test_data_Y)\n",
    "test_data_X = np.array(test_data_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  1, -1, ...,  1,  1, -1])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.68      0.65      0.66      2390\n",
      "          1       0.83      0.85      0.84      4932\n",
      "\n",
      "avg / total       0.78      0.79      0.78      7322\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "text_clf = Pipeline([('vect', CountVectorizer(\n",
    "                             analyzer = \"word\",   \\\n",
    "                             tokenizer = None,    \\\n",
    "                             preprocessor = None, \\\n",
    "                             stop_words = None,   \\\n",
    "                             max_features = 500)),\n",
    "                      ('tfidf', TfidfTransformer()),\n",
    "                      ('clf', RandomForestClassifier(n_estimators = 100)),\n",
    "])\n",
    "\n",
    "text_clf = text_clf.fit( X_train,  y_train)\n",
    "\n",
    "\n",
    "predicted = text_clf.predict(X_test)\n",
    "print(metrics.classification_report(y_test, predicted, target_names=['0', '1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.50      1.00      0.67         2\n",
      "          1       1.00      0.90      0.95        21\n",
      "\n",
      "avg / total       0.96      0.91      0.93        23\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predicted = text_clf.predict(test_data_X)\n",
    "print(metrics.classification_report(test_data_Y, predicted, target_names=['0', '1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.87      ,  0.13      ],\n",
       "       [ 0.85      ,  0.15      ],\n",
       "       [ 0.2       ,  0.8       ],\n",
       "       [ 0.2       ,  0.8       ],\n",
       "       [ 0.12      ,  0.88      ],\n",
       "       [ 0.01      ,  0.99      ],\n",
       "       [ 0.11      ,  0.89      ],\n",
       "       [ 0.59      ,  0.41      ],\n",
       "       [ 0.14      ,  0.86      ],\n",
       "       [ 0.45      ,  0.55      ],\n",
       "       [ 0.1       ,  0.9       ],\n",
       "       [ 0.12      ,  0.88      ],\n",
       "       [ 0.188     ,  0.812     ],\n",
       "       [ 0.02      ,  0.98      ],\n",
       "       [ 0.38      ,  0.62      ],\n",
       "       [ 0.49708661,  0.50291339],\n",
       "       [ 0.4075    ,  0.5925    ],\n",
       "       [ 0.51713974,  0.48286026],\n",
       "       [ 0.105     ,  0.895     ],\n",
       "       [ 0.15      ,  0.85      ],\n",
       "       [ 0.21416667,  0.78583333],\n",
       "       [ 0.08      ,  0.92      ],\n",
       "       [ 0.12      ,  0.88      ]])"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clf.predict_proba(test_data_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pretraining with TFIDF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_bar_chart(input_list, chart_title):\n",
    "    x_axis = []\n",
    "    y_axis = []\n",
    "    for item in input_list:\n",
    "        x_axis.append(item[0])\n",
    "        y_axis.append(item[1])\n",
    "    data = [go.Bar(\n",
    "                x = x_axis,\n",
    "                y = y_axis\n",
    "        )]\n",
    "\n",
    "    layout = go.Layout(\n",
    "        title = chart_title,\n",
    "    )\n",
    "    fig = go.Figure(data=data, layout=layout)\n",
    "    py.iplot(fig, filename='basic-bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def display_scores(vectorizer, tfidf_result):\n",
    "    # http://stackoverflow.com/questions/16078015/\n",
    "    scores = zip(vectorizer.get_feature_names(),\n",
    "                 np.asarray(tfidf_result.sum(axis=0)).ravel())\n",
    "    sorted_scores = sorted(scores, key=lambda x: x[1], reverse=True)\n",
    "    index_scores = []\n",
    "    for index, item in enumerate(sorted_scores):\n",
    "        index_scores.append((index, item[1]))\n",
    "        \n",
    "    generate_bar_chart(index_scores, 'TFIDF Score')\n",
    "    return sorted_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Utilizing TFIDF to delete useless words.\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf = tfidf_vectorizer.fit_transform(corpus)\n",
    "tfidf_features = tfidf_vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/phejimlin/anaconda3/envs/tensorflow_3.5/lib/python3.5/site-packages/plotly/plotly/plotly.py:218: UserWarning:\n",
      "\n",
      "Woah there! Look at all those points! Due to browser limitations, the Plotly SVG drawing functions have a hard time graphing more than 500k data points for line charts, or 40k points for other types of charts. Here are some suggestions:\n",
      "(1) Use the `plotly.graph_objs.Scattergl` trace object to generate a WebGl graph.\n",
      "(2) Trying using the image API to return an image instead of a graph URL\n",
      "(3) Use matplotlib\n",
      "(4) See if you can create your visualization with fewer data points\n",
      "\n",
      "If the visualization you're using aggregates points (e.g., box plot, histogram, etc.) you can disregard this warning.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High five! You successfuly sent some data to your account on plotly. View your plot in your browser at https://plot.ly/~phejimlin/0 or inside your plot.ly account where it is named 'basic-bar'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/phejimlin/anaconda3/envs/tensorflow_3.5/lib/python3.5/site-packages/plotly/api/v1/clientresp.py:40: UserWarning:\n",
      "\n",
      "Estimated Draw Time Slow\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sorted_scores = display_scores(tfidf_vectorizer, tfidf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Bag of words to select top n = 400\n",
    "bag_of_words = [word[0] for word in sorted_scores[:401]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating the bag of words...\n",
      "\n",
      "(17084, 401)\n",
      "(7322, 401)\n"
     ]
    }
   ],
   "source": [
    "print(\"Creating the bag of words...\\n\")\n",
    "\n",
    "# Initialize the \"CountVectorizer\" object, which is scikit-learn's\n",
    "# bag of words tool.  \n",
    "vectorizer = CountVectorizer(vocabulary=bag_of_words) \n",
    "\n",
    "# fit_transform() does two functions: First, it fits the model\n",
    "# and learns the vocabulary; second, it transforms our training data\n",
    "# into feature vectors. The input to fit_transform should be a list of \n",
    "# strings.\n",
    "train_data_features = vectorizer.fit_transform(X_train)\n",
    "test_data_features = vectorizer.transform(X_test)\n",
    "\n",
    "print(train_data_features.shape)\n",
    "print(test_data_features.shape)\n",
    "\n",
    "# Numpy arrays are easy to work with, so convert the result to an \n",
    "# array\n",
    "train_data_features = train_data_features.toarray()\n",
    "test_data_features = test_data_features.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the random forest...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.63      0.65      2390\n",
      "          1       0.83      0.85      0.84      4932\n",
      "\n",
      "avg / total       0.78      0.78      0.78      7322\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Training the random forest...\")\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Initialize a Random Forest classifier with 100 trees\n",
    "forest = RandomForestClassifier(n_estimators = 100) \n",
    "\n",
    "# Fit the forest to the training set, using the bag of words as \n",
    "# features and the sentiment labels as the response variable\n",
    "#\n",
    "# This may take a few minutes to run\n",
    "forest = forest.fit(train_data_features,  y_train)\n",
    "\n",
    "predicted = forest.predict(test_data_features)\n",
    "\n",
    "print(metrics.classification_report(y_test, predicted, target_names=['0', '1']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.62      0.64      2390\n",
      "          1       0.82      0.85      0.84      4932\n",
      "\n",
      "avg / total       0.77      0.78      0.77      7322\n",
      "\n",
      "[[ 0.9         0.1       ]\n",
      " [ 0.94        0.06      ]\n",
      " [ 0.1         0.9       ]\n",
      " [ 0.31        0.69      ]\n",
      " [ 0.09        0.91      ]\n",
      " [ 0.005       0.995     ]\n",
      " [ 0.24        0.76      ]\n",
      " [ 0.44        0.56      ]\n",
      " [ 0.19        0.81      ]\n",
      " [ 0.39        0.61      ]\n",
      " [ 0.16        0.84      ]\n",
      " [ 0.08        0.92      ]\n",
      " [ 0.05        0.95      ]\n",
      " [ 0.05        0.95      ]\n",
      " [ 0.56        0.44      ]\n",
      " [ 0.46485714  0.53514286]\n",
      " [ 0.33        0.67      ]\n",
      " [ 0.72437121  0.27562879]\n",
      " [ 0.24616667  0.75383333]\n",
      " [ 0.22        0.78      ]\n",
      " [ 0.28333333  0.71666667]\n",
      " [ 0.          1.        ]\n",
      " [ 0.13        0.87      ]]\n"
     ]
    }
   ],
   "source": [
    "text_clf = Pipeline([('vect', CountVectorizer(vocabulary=bag_of_words)),\n",
    "                      ('clf', RandomForestClassifier(n_estimators = 100)),\n",
    "])\n",
    "\n",
    "text_clf = text_clf.fit(X_train,  y_train)\n",
    "\n",
    "\n",
    "predicted = text_clf.predict(X_test)\n",
    "print(metrics.classification_report(y_test, predicted, target_names=['0', '1']))\n",
    "print(text_clf.predict_proba(test_data_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "# now you can save it to a file\n",
    "with open('TFIDF_RandomForestClassifier.pkl', 'wb') as f:\n",
    "    pickle.dump(text_clf, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.62      0.46      0.53      2390\n",
      "          1       0.77      0.86      0.81      4932\n",
      "\n",
      "avg / total       0.72      0.73      0.72      7322\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Naive_bayes \n",
    "Multinomial_clf = Pipeline([('vect', CountVectorizer(vocabulary=bag_of_words)),\n",
    "                      ('clf', MultinomialNB()),\n",
    "])\n",
    "Multinomial_clf = Multinomial_clf.fit(X_train, y_train)\n",
    "\n",
    "predicted = Multinomial_clf.predict(X_test)\n",
    "\n",
    "print(metrics.classification_report(y_test, predicted, target_names=['0', '1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('Naive_bayes_Classifier.pkl', 'wb') as f:\n",
    "    pickle.dump(Multinomial_clf, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the SVM...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.62      0.46      0.53      2390\n",
      "          1       0.77      0.86      0.81      4932\n",
      "\n",
      "avg / total       0.72      0.73      0.72      7322\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SVM\n",
    "print(\"Training the SVM...\")\n",
    "LinearSVC_clf = Pipeline([('vect', CountVectorizer(vocabulary=bag_of_words)),\n",
    "                      ('clf', LinearSVC()),\n",
    "])\n",
    "\n",
    "LinearSVC_clf = LinearSVC_clf.fit(X_train, y_train)\n",
    "predicted = clf.predict(X_test)\n",
    "print(metrics.classification_report(y_test, predicted, target_names=['0', '1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('LinearSVC_Classifier.pkl', 'wb') as f:\n",
    "    pickle.dump(LinearSVC_clf, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the DecisionTree...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.61      0.78      0.69      2390\n",
      "          1       0.88      0.76      0.82      4932\n",
      "\n",
      "avg / total       0.79      0.77      0.77      7322\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Training the DecisionTree...\")\n",
    "DecisionTree_clf = Pipeline([('vect', CountVectorizer(vocabulary=bag_of_words)),\n",
    "                      ('clf', DecisionTreeClassifier(criterion='entropy', \n",
    "                              max_depth=3, \n",
    "                              random_state=0)),\n",
    "])\n",
    "\n",
    "# criterion : impurity function\n",
    "# max_depth : maximum depth of tree\n",
    "# random_state : seed of random number generator\n",
    "DecisionTree_clf=DecisionTree_clf.fit(X_train, y_train)\n",
    "predicted = DecisionTree_clf.predict(X_test)\n",
    "print(metrics.classification_report(y_test, predicted, target_names=['0', '1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('DecisionTree_Classifier.pkl', 'wb') as f:\n",
    "    pickle.dump(DecisionTree_clf, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load modle with pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# and later you can load it\n",
    "with open('TFIDF_RandomForestClassifier.pkl', 'rb') as f:\n",
    "    clf = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.9         0.1       ]\n",
      " [ 0.94        0.06      ]\n",
      " [ 0.1         0.9       ]\n",
      " [ 0.31        0.69      ]\n",
      " [ 0.09        0.91      ]\n",
      " [ 0.005       0.995     ]\n",
      " [ 0.24        0.76      ]\n",
      " [ 0.44        0.56      ]\n",
      " [ 0.19        0.81      ]\n",
      " [ 0.39        0.61      ]\n",
      " [ 0.16        0.84      ]\n",
      " [ 0.08        0.92      ]\n",
      " [ 0.05        0.95      ]\n",
      " [ 0.05        0.95      ]\n",
      " [ 0.56        0.44      ]\n",
      " [ 0.46485714  0.53514286]\n",
      " [ 0.33        0.67      ]\n",
      " [ 0.72437121  0.27562879]\n",
      " [ 0.24616667  0.75383333]\n",
      " [ 0.22        0.78      ]\n",
      " [ 0.28333333  0.71666667]\n",
      " [ 0.          1.        ]\n",
      " [ 0.13        0.87      ]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.62      0.64      2390\n",
      "          1       0.82      0.85      0.84      4932\n",
      "\n",
      "avg / total       0.77      0.78      0.77      7322\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(clf.predict_proba(test_data_X))\n",
    "predicted = clf.predict(X_test)\n",
    "print(metrics.classification_report(y_test, predicted, target_names=['0', '1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
